import logging
import requests
import json
import asyncio
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import Updater, CommandHandler, MessageHandler, Filters, CallbackContext, CallbackQueryHandler
from dotenv import load_dotenv
import os

# MCP imports
from mcp import ClientSession
from mcp.client.websocket import websocket_client

# Load environment variables from the secret files
load_dotenv(dotenv_path='.secrets/bot-token.env')
load_dotenv(dotenv_path='.secrets/deepseek-api-key.env')

# Enable logging
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)

logger = logging.getLogger(__name__)

# Get the bot token from environment variables
TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')

# DeepSeek API configuration (using your paid account)
DEEPSEEK_API_KEY = os.getenv('DEEPSEEK_API_KEY')
DEEPSEEK_API_URL = 'https://api.deepseek.com/v1/chat/completions'
# Using DeepSeek Chat - your paid model
MODEL_NAME = 'deepseek-chat'  # Main DeepSeek model

# MCP configuration
MCP_SERVER_URL = "ws://localhost:8080/mcp"

def start(update: Update, context: CallbackContext) -> None:
    """Send a message when the command /start is issued."""
    user = update.effective_user
    update.message.reply_text('–ü—Ä–∏–≤–µ—Ç! –≠—Ç–æ –±–æ—Ç —Å –º–æ–¥–µ–ª—å—é DeepSeek Chat —á–µ—Ä–µ–∑ DeepSeek API. –ó–∞–¥–∞–≤–∞–π –ª—é–±—ã–µ –≤–æ–ø—Ä–æ—Å—ã!')

def help_command(update: Update, context: CallbackContext) -> None:
    """Send a message when the command /help is issued."""
    help_text = (
        '–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:\n'
        '/start - –ù–∞—á–∞—Ç—å —Ä–∞–±–æ—Ç—É —Å –±–æ—Ç–æ–º\n'
        '/help - –ü–æ–∫–∞–∑–∞—Ç—å —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ\n'
        '/stats - –ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤ –∏ —Å–∂–∞—Ç–∏—è\n'
        '/compress - –°–∂–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –≤—Ä—É—á–Ω—É—é\n'
        '/clear - –û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞\n\n'
        'üìã Yandex Tracker –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è:\n'
        '–°–ø—Ä–æ—Å–∏—Ç–µ –ø—Ä–æ "–∑–∞–¥–∞—á–∏" –∏–ª–∏ "tracker" - –±–æ—Ç –ø–æ–ª—É—á–∏—Ç –∞–∫—Ç—É–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á —á–µ—Ä–µ–∑ MCP!\n\n'
        '‚è∞ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è:\n'
        '–ö–∞–∂–¥—ã–µ 15 –º–∏–Ω—É—Ç –±–æ—Ç –ø—Ä–∏—Å—ã–ª–∞–µ—Ç —Å–≤–æ–¥–∫—É –∑–∞–¥–∞—á –∏–∑ Yandex Tracker\n\n'
        'üí° –ê–≤—Ç–æ—Å–∂–∞—Ç–∏–µ: –ö–∞–∂–¥—ã–µ 10 —Å–æ–æ–±—â–µ–Ω–∏–π –∏—Å—Ç–æ—Ä–∏—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–∂–∏–º–∞–µ—Ç—Å—è –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤!\n\n'
        '–ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ –≤–æ–ø—Ä–æ—Å, –∏ —è –æ—Ç–≤–µ—á—É —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏ DeepSeek Chat!'
    )
    update.message.reply_text(help_text)

def stats_command(update: Update, context: CallbackContext) -> None:
    """Show token usage statistics."""
    if 'token_stats' not in context.user_data or context.user_data['token_stats']['total_requests'] == 0:
        update.message.reply_text('üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—É—Å—Ç–∞. –û—Ç–ø—Ä–∞–≤—å—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –Ω–∞—á–∞–ª–∞.')
        return

    stats = context.user_data['token_stats']

    # Calculate averages
    avg_total = stats['total_tokens'] / stats['total_requests']
    avg_prompt = stats['total_prompt_tokens'] / stats['total_requests']
    avg_completion = stats['total_completion_tokens'] / stats['total_requests']

    stats_text = (
        f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤\n"
        f"{'=' * 35}\n\n"
        f"–í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {stats['total_requests']}\n\n"
        f"–û–±—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:\n"
        f"‚Ä¢ –í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤: {stats['total_tokens']}\n"
        f"‚Ä¢ –¢–æ–∫–µ–Ω–æ–≤ –≤ –∑–∞–ø—Ä–æ—Å–∞—Ö: {stats['total_prompt_tokens']}\n"
        f"‚Ä¢ –¢–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–∞—Ö: {stats['total_completion_tokens']}\n\n"
        f"–°—Ä–µ–¥–Ω–µ–µ –Ω–∞ –∑–∞–ø—Ä–æ—Å:\n"
        f"‚Ä¢ –í—Å–µ–≥–æ: {avg_total:.1f} —Ç–æ–∫–µ–Ω–æ–≤\n"
        f"‚Ä¢ –ó–∞–ø—Ä–æ—Å: {avg_prompt:.1f} —Ç–æ–∫–µ–Ω–æ–≤\n"
        f"‚Ä¢ –û—Ç–≤–µ—Ç: {avg_completion:.1f} —Ç–æ–∫–µ–Ω–æ–≤\n"
    )

    # Show compression statistics
    if 'compression_stats' in context.user_data and context.user_data['compression_stats']['total_compressions'] > 0:
        comp_stats = context.user_data['compression_stats']
        stats_text += f"\n{'=' * 35}\n"
        stats_text += "üóúÔ∏è –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∂–∞—Ç–∏—è:\n\n"
        stats_text += f"‚Ä¢ –í—Å–µ–≥–æ —Å–∂–∞—Ç–∏–π: {comp_stats['total_compressions']}\n"
        stats_text += f"‚Ä¢ –°–æ–æ–±—â–µ–Ω–∏–π —Å–∂–∞—Ç–æ: {comp_stats['messages_compressed']}\n"
        stats_text += f"‚Ä¢ –¢–æ–∫–µ–Ω–æ–≤ —Å—ç–∫–æ–Ω–æ–º–ª–µ–Ω–æ: ~{comp_stats['tokens_saved']}\n"

    # Show last 5 requests
    if stats['requests_history']:
        stats_text += f"\n{'=' * 35}\n"
        stats_text += f"–ü–æ—Å–ª–µ–¥–Ω–∏–µ {min(5, len(stats['requests_history']))} –∑–∞–ø—Ä–æ—Å–æ–≤:\n\n"

        for i, req in enumerate(stats['requests_history'][-5:], 1):
            stats_text += (
                f"{i}. {req['timestamp']}\n"
                f"   –î–ª–∏–Ω–∞ –≤–æ–ø—Ä–æ—Å–∞: {req['question_length']} —Å–∏–º–≤–æ–ª–æ–≤\n"
                f"   –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {req['response_length']} —Å–∏–º–≤–æ–ª–æ–≤\n"
                f"   –¢–æ–∫–µ–Ω—ã: {req['tokens']['total_tokens']} "
                f"({req['tokens']['prompt_tokens']}+{req['tokens']['completion_tokens']})\n\n"
            )

    update.message.reply_text(stats_text)

def clear_command(update: Update, context: CallbackContext) -> None:
    """Clear conversation history."""
    if 'conversation_history' in context.user_data:
        context.user_data['conversation_history'] = []
    update.message.reply_text('üóëÔ∏è –ò—Å—Ç–æ—Ä–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –æ—á–∏—â–µ–Ω–∞!')

def compress_command(update: Update, context: CallbackContext) -> None:
    """Manually compress conversation history."""
    if 'conversation_history' not in context.user_data:
        update.message.reply_text('‚ùå –ò—Å—Ç–æ—Ä–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –ø—É—Å—Ç–∞!')
        return

    history = context.user_data['conversation_history']
    non_system_messages = [msg for msg in history if msg.get('role') != 'system']

    if len(non_system_messages) < 2:
        update.message.reply_text('‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è —Å–∂–∞—Ç–∏—è (–º–∏–Ω–∏–º—É–º 2)')
        return

    update.message.reply_text('üóúÔ∏è –°–∂–∏–º–∞—é –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞...')

    compression_result = compress_conversation_history(context, force=True)

    if compression_result.get('compressed'):
        # Reset message counter after manual compression
        old_counter = context.user_data.get('message_counter', 0)
        context.user_data['message_counter'] = 0

        response = (
            f"‚úÖ –ò—Å—Ç–æ—Ä–∏—è —É—Å–ø–µ—à–Ω–æ —Å–∂–∞—Ç–∞!\n\n"
            f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∂–∞—Ç–∏—è:\n"
            f"‚Ä¢ –°–æ–æ–±—â–µ–Ω–∏–π –¥–æ: {compression_result['messages_before']}\n"
            f"‚Ä¢ –°–æ–æ–±—â–µ–Ω–∏–π –ø–æ—Å–ª–µ: {compression_result['messages_after']}\n"
            f"‚Ä¢ –¢–æ–∫–µ–Ω–æ–≤ –¥–æ: ~{compression_result['tokens_before']}\n"
            f"‚Ä¢ –¢–æ–∫–µ–Ω–æ–≤ –ø–æ—Å–ª–µ: ~{compression_result['tokens_after']}\n"
            f"‚Ä¢ –°—ç–∫–æ–Ω–æ–º–ª–µ–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: ~{compression_result['tokens_saved']}\n"
            f"‚Ä¢ –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∂–∞—Ç–∏—è: {compression_result['compression_ratio']}%\n"
            f"‚Ä¢ –≠–∫–æ–Ω–æ–º–∏—è: {100 - compression_result['compression_ratio']:.0f}%\n\n"
            f"üîÑ –°—á—ë—Ç—á–∏–∫ —Å–æ–æ–±—â–µ–Ω–∏–π —Å–±—Ä–æ—à–µ–Ω (–±—ã–ª–æ: #{old_counter})"
        )
        update.message.reply_text(response)
    else:
        update.message.reply_text(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∂–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é: {compression_result.get('reason', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")

def ask_question(update: Update, context: CallbackContext) -> None:
    """Send the user's question to DeepSeek API and return the response."""
    if update.message is None or update.message.text is None:
        update.message.reply_text("Sorry, I couldn't process that message.")
        return

    user_question = update.message.text

    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å chat_id –ø—Ä–∏ –ø–µ—Ä–≤–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏
    if 'admin_chat_id' not in context.bot_data:
        context.bot_data['admin_chat_id'] = update.message.chat_id
        logger.info(f"Saved admin_chat_id: {update.message.chat_id}")

    # Initialize conversation history and current date in context if it doesn't exist
    if 'conversation_history' not in context.user_data:
        context.user_data['conversation_history'] = []

    # Initialize token statistics
    if 'token_stats' not in context.user_data:
        context.user_data['token_stats'] = {
            'total_requests': 0,
            'total_tokens': 0,
            'total_prompt_tokens': 0,
            'total_completion_tokens': 0,
            'requests_history': []
        }

    # Initialize message counter
    if 'message_counter' not in context.user_data:
        context.user_data['message_counter'] = 0

    # Increment message counter
    context.user_data['message_counter'] += 1
    current_message_num = context.user_data['message_counter']

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –ø—Ä–æ –∑–∞–¥–∞—á–∏ –∏–∑ Tracker
    keywords = ["–∑–∞–¥–∞—á", "task", "tracker", "issue", "—Ç—Ä–µ–∫–µ—Ä"]
    message_lower = user_question.lower()

    logger.info(f"Checking message for tracker keywords: '{message_lower}'")
    keyword_found = any(keyword in message_lower for keyword in keywords)
    logger.info(f"Keyword found: {keyword_found}")

    if keyword_found:
        logger.info("Detected tracker-related question, calling MCP...")
        try:
            tasks_json = call_mcp_tool_sync("get-tracker-tasks")
            logger.info(f"MCP response received: {len(tasks_json) if tasks_json else 0} chars")

            if tasks_json:
                # –î–æ–±–∞–≤–∏—Ç—å –∑–∞–¥–∞—á–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
                tracker_context = {
                    "role": "system",
                    "content": f"–°–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á –∏–∑ Yandex Tracker:\n{tasks_json}\n\n–ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç–∏ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."
                }
                # –í—Å—Ç–∞–≤–∏—Ç—å –≤ –Ω–∞—á–∞–ª–æ –∏—Å—Ç–æ—Ä–∏–∏
                context.user_data['conversation_history'].insert(0, tracker_context)
                logger.info("Added tracker tasks to conversation context")
            else:
                logger.error("Failed to get tasks from MCP")

        except Exception as e:
            logger.error(f"Error calling MCP: {e}")
            update.message.reply_text("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∑–∞–¥–∞—á–∏ –∏–∑ Tracker")

    # Add user message to conversation history
    context.user_data['conversation_history'].append({
        "role": "user",
        "content": user_question
    })

    # Auto-compress every 10 messages (excluding system messages)
    non_system_messages = [msg for msg in context.user_data['conversation_history'] if msg.get('role') != 'system']
    if len(non_system_messages) >= 10:
        compression_result = compress_conversation_history(context)
        if compression_result.get('compressed'):
            # Reset message counter after compression
            context.user_data['message_counter'] = 0
            update.message.reply_text(
                f"üóúÔ∏è –ê–≤—Ç–æ—Å–∂–∞—Ç–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ (–ø–æ—Å–ª–µ —Å–æ–æ–±—â–µ–Ω–∏—è #{current_message_num}):\n"
                f"‚Ä¢ –°–∂–∞—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {compression_result['messages_before']}\n"
                f"‚Ä¢ –¢–æ–∫–µ–Ω–æ–≤ –±—ã–ª–æ: ~{compression_result['tokens_before']}\n"
                f"‚Ä¢ –¢–æ–∫–µ–Ω–æ–≤ —Å—Ç–∞–ª–æ: ~{compression_result['tokens_after']}\n"
                f"‚Ä¢ –≠–∫–æ–Ω–æ–º–∏—è: ~{compression_result['tokens_saved']} —Ç–æ–∫–µ–Ω–æ–≤ ({100 - compression_result['compression_ratio']:.0f}%)\n"
                f"‚Ä¢ –°—á—ë—Ç—á–∏–∫ —Å–æ–æ–±—â–µ–Ω–∏–π —Å–±—Ä–æ—à–µ–Ω!"
            )

    # Estimate input length for warning
    estimated_input_chars = sum(len(msg['content']) for msg in context.user_data['conversation_history'])
    estimated_input_tokens = estimated_input_chars // 4  # Rough estimate: 1 token ‚âà 4 chars

    # Warn if input is very long
    if estimated_input_tokens > 7000:
        update.message.reply_text(
            "‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: –û—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å!\n"
            f"–ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ {estimated_input_tokens} —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∏—Å—Ç–æ—Ä–∏–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞.\n"
            "–ú–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤–µ—Å—å –∫–æ–Ω—Ç–µ–∫—Å—Ç."
        )

    # Call DeepSeek API with conversation history
    gpt_response, token_usage = call_deepseek_api(context.user_data['conversation_history'])

    # Add assistant response to conversation history
    context.user_data['conversation_history'].append({
        "role": "assistant",
        "content": gpt_response
    })

    # Update token statistics
    context.user_data['token_stats']['total_requests'] += 1
    context.user_data['token_stats']['total_tokens'] += token_usage['total_tokens']
    context.user_data['token_stats']['total_prompt_tokens'] += token_usage['prompt_tokens']
    context.user_data['token_stats']['total_completion_tokens'] += token_usage['completion_tokens']

    # Add to request history (keep last 20 requests)
    from datetime import datetime
    context.user_data['token_stats']['requests_history'].append({
        'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        'question_length': len(user_question),
        'response_length': len(gpt_response),
        'tokens': token_usage
    })
    if len(context.user_data['token_stats']['requests_history']) > 20:
        context.user_data['token_stats']['requests_history'].pop(0)

    # Format response with token information
    token_info = (
        f"\n\nüìä –°–æ–æ–±—â–µ–Ω–∏–µ #{current_message_num} | –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤:\n"
        f"‚Ä¢ –ó–∞–ø—Ä–æ—Å: {token_usage['prompt_tokens']}\n"
        f"‚Ä¢ –û—Ç–≤–µ—Ç: {token_usage['completion_tokens']}\n"
        f"‚Ä¢ –í—Å–µ–≥–æ: {token_usage['total_tokens']}"
    )

    # Send the response directly to the user with token info
    full_response = gpt_response + token_info
    update.message.reply_text(full_response)

def create_conversation_summary(messages) -> str:
    """Create a summary of conversation history using DeepSeek API.

    Args:
        messages: List of conversation messages

    Returns:
        str: Summary of the conversation
    """
    if not messages:
        return ""

    # Prepare prompt for summarization
    conversation_text = "\n".join([
        f"{msg['role'].upper()}: {msg['content']}"
        for msg in messages
    ])

    summary_prompt = f"""–°–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞.
–°–æ—Ö—Ä–∞–Ω–∏ –í–°–Æ –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, —Ñ–∞–∫—Ç—ã, –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –≤—ã–≤–æ–¥—ã.
–†–µ–∑—é–º–µ –¥–æ–ª–∂–Ω–æ –ø–æ–∑–≤–æ–ª–∏—Ç—å –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.

–î–∏–∞–ª–æ–≥:
{conversation_text}

–ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ (–Ω–∞ —Ä—É—Å—Å–∫–æ–º):"""

    summary_messages = [
        {"role": "system", "content": "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–∑–¥–∞—ë—Ç –∫—Ä–∞—Ç–∫–∏–µ —Ä–µ–∑—é–º–µ –¥–∏–∞–ª–æ–≥–æ–≤, —Å–æ—Ö—Ä–∞–Ω—è—è –≤—Å—é –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é."},
        {"role": "user", "content": summary_prompt}
    ]

    try:
        response_text, _ = call_deepseek_api(summary_messages)
        return response_text
    except Exception as e:
        logger.error(f"Error creating summary: {e}")
        # Fallback: create simple summary
        return f"–û–±—Å—É–∂–¥–∞–ª–æ—Å—å {len(messages)} —Å–æ–æ–±—â–µ–Ω–∏–π. –¢–µ–º—ã: {', '.join(set([msg['content'][:30] + '...' for msg in messages[:3]]))}"

def compress_conversation_history(context: CallbackContext, force: bool = False) -> dict:
    """Compress conversation history by creating a summary.

    Args:
        context: Telegram context with user_data
        force: Force compression even if threshold not reached

    Returns:
        dict: Compression statistics
    """
    if 'conversation_history' not in context.user_data:
        return {'compressed': False, 'reason': 'No history'}

    history = context.user_data['conversation_history']

    # Skip if history is too short (unless forced)
    if len(history) < 10 and not force:
        return {'compressed': False, 'reason': 'History too short', 'messages': len(history)}

    # Calculate tokens before compression
    chars_before = sum(len(msg['content']) for msg in history)
    tokens_before = chars_before // 4

    # Create summary of all messages except system messages
    messages_to_summarize = [msg for msg in history if msg.get('role') != 'system']

    if not messages_to_summarize:
        return {'compressed': False, 'reason': 'No messages to compress'}

    logger.info(f"Compressing {len(messages_to_summarize)} messages...")
    summary = create_conversation_summary(messages_to_summarize)

    # Replace history with summary
    context.user_data['conversation_history'] = [
        {
            "role": "system",
            "content": f"–ü—Ä–µ–¥—ã–¥—É—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ (—Ä–µ–∑—é–º–µ {len(messages_to_summarize)} —Å–æ–æ–±—â–µ–Ω–∏–π):\n{summary}"
        }
    ]

    # Calculate tokens after compression
    chars_after = len(summary)
    tokens_after = chars_after // 4

    # Update compression statistics
    if 'compression_stats' not in context.user_data:
        context.user_data['compression_stats'] = {
            'total_compressions': 0,
            'tokens_saved': 0,
            'messages_compressed': 0
        }

    context.user_data['compression_stats']['total_compressions'] += 1
    context.user_data['compression_stats']['tokens_saved'] += (tokens_before - tokens_after)
    context.user_data['compression_stats']['messages_compressed'] += len(messages_to_summarize)

    return {
        'compressed': True,
        'messages_before': len(messages_to_summarize),
        'messages_after': 1,
        'tokens_before': tokens_before,
        'tokens_after': tokens_after,
        'tokens_saved': tokens_before - tokens_after,
        'compression_ratio': round(tokens_after / tokens_before * 100, 1) if tokens_before > 0 else 0
    }

def call_deepseek_api(messages) -> tuple:
    """Call DeepSeek API and return the response with token usage.

    Returns:
        tuple: (response_text, token_usage_dict) where token_usage_dict contains:
            - total_tokens: total tokens used
            - prompt_tokens: tokens in the prompt
            - completion_tokens: tokens in the completion
    """
    if not DEEPSEEK_API_KEY:
        return ("DeepSeek API key not configured. Please check your environment variables.",
                {"total_tokens": 0, "prompt_tokens": 0, "completion_tokens": 0})

    headers = {
        'Authorization': f'Bearer {DEEPSEEK_API_KEY}',
        'Content-Type': 'application/json'
    }

    # Add system message if not present
    formatted_messages = []
    if not any(msg.get('role') == 'system' for msg in messages):
        formatted_messages.append({
            "role": "system",
            "content": "–¢—ã ‚Äî –ø–æ–ª–µ–∑–Ω—ã–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç–æ—á–Ω–æ –∏ –ø–æ–ª–µ–∑–Ω–æ."
        })

    # Add conversation history
    formatted_messages.extend(messages)

    payload = {
        "model": MODEL_NAME,
        "messages": formatted_messages,
        "temperature": 0.7,
        "max_tokens": 2000
    }

    try:
        response = requests.post(DEEPSEEK_API_URL, headers=headers, data=json.dumps(payload))
        response.raise_for_status()
        result = response.json()

        # Extract response text
        response_text = result['choices'][0]['message']['content']

        # Extract token usage from response
        usage = result.get('usage', {})

        # Get token counts
        prompt_tokens = usage.get('prompt_tokens', 0)
        completion_tokens = usage.get('completion_tokens', 0)
        total_tokens = usage.get('total_tokens', 0)

        token_usage = {
            'total_tokens': total_tokens,
            'prompt_tokens': prompt_tokens,
            'completion_tokens': completion_tokens
        }

        logger.info(f"Token usage: Total={total_tokens}, Prompt={prompt_tokens}, Completion={completion_tokens}")

        return (response_text, token_usage)
    except Exception as e:
        logger.error(f"Error calling DeepSeek API: {e}")
        if hasattr(e, 'response') and e.response is not None:
            logger.error(f"Response status: {e.response.status_code}")
            logger.error(f"Response body: {e.response.text}")
        error_msg = f"Sorry, I encountered an error while processing your request: {str(e)}"
        return (error_msg, {"total_tokens": 0, "prompt_tokens": 0, "completion_tokens": 0})

# MCP Client functions
async def call_mcp_tool(tool_name: str, arguments: dict = None):
    """–í—ã–∑–æ–≤ MCP tool —á–µ—Ä–µ–∑ WebSocket –∏ –ø–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞."""
    try:
        logger.info(f"Connecting to MCP server at {MCP_SERVER_URL}")
        async with websocket_client(MCP_SERVER_URL) as (read, write):
            logger.info("WebSocket connection established")
            async with ClientSession(read, write) as session:
                logger.info("MCP session created")

                # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å timeout
                await asyncio.wait_for(session.initialize(), timeout=10.0)
                logger.info("Session initialized")

                # –í—ã–∑–æ–≤ tool —Å timeout
                logger.info(f"Calling tool: {tool_name}")
                result = await asyncio.wait_for(
                    session.call_tool(tool_name, arguments or {}),
                    timeout=15.0
                )
                logger.info(f"Tool call completed")

                # –ò–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                if result.content and len(result.content) > 0:
                    logger.info(f"Result content: {len(result.content[0].text)} chars")
                    return result.content[0].text
                else:
                    logger.warning("No content in result")
                return None
    except asyncio.TimeoutError:
        logger.error(f"Timeout calling MCP tool: {tool_name}")
        return None
    except Exception as e:
        logger.error(f"Error calling MCP tool: {e}", exc_info=True)
        return None


def call_mcp_tool_sync(tool_name: str, arguments: dict = None):
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –≤—ã–∑–æ–≤–∞ async MCP tool."""
    loop = asyncio.new_event_loop()
    try:
        return loop.run_until_complete(call_mcp_tool(tool_name, arguments))
    finally:
        loop.close()


def send_tasks_summary(context: CallbackContext):
    """–û—Ç–ø—Ä–∞–≤–∫–∞ —Å–≤–æ–¥–∫–∏ –∑–∞–¥–∞—á –∫–∞–∂–¥—ã–µ 30 –º–∏–Ω—É—Ç."""
    if 'admin_chat_id' not in context.bot_data:
        logger.warning("admin_chat_id not set, skipping summary")
        return

    try:
        # –ü–æ–ª—É—á–∞–µ–º –∑–∞–¥–∞—á–∏ —á–µ—Ä–µ–∑ MCP
        tasks_json = call_mcp_tool_sync("get-tracker-tasks")

        if not tasks_json:
            logger.error("Failed to get tasks from MCP")
            return

        # –ü–∞—Ä—Å–∏–º JSON
        tasks = json.loads(tasks_json)

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å–≤–æ–¥–∫—É
        if isinstance(tasks, dict) and 'error' in tasks:
            summary = f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∑–∞–¥–∞—á:\n{tasks['error']}"
        elif isinstance(tasks, list):
            if len(tasks) == 0:
                summary = "üìã –ó–∞–¥–∞—á –≤ Yandex Tracker –Ω–µ—Ç"
            else:
                summary = f"üìã –°–≤–æ–¥–∫–∞ –∑–∞–¥–∞—á –∏–∑ Yandex Tracker ({len(tasks)} —à—Ç.):\n\n"
                for task in tasks[:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –º–∞–∫—Å–∏–º—É–º 10 –∑–∞–¥–∞—á
                    summary += f"üîπ {task.get('key')}: {task.get('summary')}\n"
                    summary += f"   –°—Ç–∞—Ç—É—Å: {task.get('status')}\n"
                    summary += f"   –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å: {task.get('assignee')}\n\n"

                if len(tasks) > 10:
                    summary += f"\n... –∏ –µ—â—ë {len(tasks) - 10} –∑–∞–¥–∞—á(–∏)"
        else:
            summary = f"üìã –ü–æ–ª—É—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ:\n{tasks_json[:500]}"

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º
        context.bot.send_message(
            chat_id=context.bot_data['admin_chat_id'],
            text=summary
        )
        logger.info(f"Sent tasks summary to {context.bot_data['admin_chat_id']}")

    except Exception as e:
        logger.error(f"Error in send_tasks_summary: {e}", exc_info=True)


def error_handler(update: Update, context: CallbackContext) -> None:
    """Log errors caused by updates."""
    logger.error(f"Update {update} caused error {context.error}")

def main() -> None:
    """Start the bot."""
    if not TOKEN:
        logger.error("TELEGRAM_BOT_TOKEN not found in environment variables")
        return

    # Create the Updater and pass it your bot's token.
    updater = Updater(TOKEN)

    # Get the dispatcher to register handlers
    dispatcher = updater.dispatcher

    # Register handlers
    dispatcher.add_handler(CommandHandler("start", start))
    dispatcher.add_handler(CommandHandler("help", help_command))
    dispatcher.add_handler(CommandHandler("stats", stats_command))
    dispatcher.add_handler(CommandHandler("compress", compress_command))
    dispatcher.add_handler(CommandHandler("clear", clear_command))
    dispatcher.add_handler(MessageHandler(Filters.text & ~Filters.command, ask_question))

    # Add error handler
    dispatcher.add_error_handler(error_handler)

    # Add periodic job for tasks summary (every 30 minutes = 1800 seconds)
    job_queue = updater.job_queue
    job_queue.run_repeating(send_tasks_summary, interval=1800, first=1800)
    logger.info("Scheduled tasks summary job (every 30 minutes)")

    # Start the Bot
    updater.start_polling()

    # Run the bot until you press Ctrl-C or the process receives SIGINT,
    # SIGTERM or SIGABRT. This should be used most of the time, since
    # start_polling() is non-blocking and will stop the bot gracefully.
    updater.idle()

if __name__ == '__main__':
    main()
