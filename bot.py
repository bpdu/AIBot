import logging
import requests
import json
import asyncio
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import Updater, CommandHandler, MessageHandler, Filters, CallbackContext, CallbackQueryHandler
from dotenv import load_dotenv
import os

# MCP imports
from mcp import ClientSession
from mcp.client.websocket import websocket_client

# RAG imports
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent / 'rag'))
try:
    from retrieval import rag_query
    RAG_AVAILABLE = True
except ImportError:
    logger.warning("RAG module not available")
    RAG_AVAILABLE = False

# Load environment variables from the secret files
load_dotenv(dotenv_path='.secrets/bot-token.env')
load_dotenv(dotenv_path='.secrets/deepseek-api-key.env')

# Enable logging
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)

logger = logging.getLogger(__name__)

# Get the bot token from environment variables
TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')

# DeepSeek API configuration (using your paid account)
DEEPSEEK_API_KEY = os.getenv('DEEPSEEK_API_KEY')
DEEPSEEK_API_URL = 'https://api.deepseek.com/v1/chat/completions'
# Using DeepSeek Chat - your paid model
MODEL_NAME = 'deepseek-chat'  # Main DeepSeek model

# MCP configuration
MCP_SERVER_URL = "ws://localhost:8080/mcp"  # Yandex Tracker
MCP_SERVER2_URL = "ws://localhost:8081/mcp"  # Translation

def start(update: Update, context: CallbackContext) -> None:
    """Send a message when the command /start is issued."""
    user = update.effective_user
    update.message.reply_text('–ü—Ä–∏–≤–µ—Ç! –≠—Ç–æ –±–æ—Ç —Å –º–æ–¥–µ–ª—å—é DeepSeek Chat —á–µ—Ä–µ–∑ DeepSeek API. –ó–∞–¥–∞–≤–∞–π –ª—é–±—ã–µ –≤–æ–ø—Ä–æ—Å—ã!')

def help_command(update: Update, context: CallbackContext) -> None:
    """Send a message when the command /help is issued."""
    help_text = (
        '–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:\n'
        '/start - –ù–∞—á–∞—Ç—å —Ä–∞–±–æ—Ç—É —Å –±–æ—Ç–æ–º\n'
        '/help - –ü–æ–∫–∞–∑–∞—Ç—å —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ\n'
        '/stats - –ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤ –∏ —Å–∂–∞—Ç–∏—è\n'
        '/compress - –°–∂–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –≤—Ä—É—á–Ω—É—é\n'
        '/clear - –û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞\n\n'
        'üìã Yandex Tracker –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è:\n'
        '–°–ø—Ä–æ—Å–∏—Ç–µ –ø—Ä–æ "–∑–∞–¥–∞—á–∏" –∏–ª–∏ "tracker" - –±–æ—Ç –ø–æ–ª—É—á–∏—Ç –∞–∫—Ç—É–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á —á–µ—Ä–µ–∑ MCP!\n\n'
        '‚è∞ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è:\n'
        '–ö–∞–∂–¥—ã–µ 15 –º–∏–Ω—É—Ç –±–æ—Ç –ø—Ä–∏—Å—ã–ª–∞–µ—Ç —Å–≤–æ–¥–∫—É –∑–∞–¥–∞—á –∏–∑ Yandex Tracker\n\n'
        'üí° –ê–≤—Ç–æ—Å–∂–∞—Ç–∏–µ: –ö–∞–∂–¥—ã–µ 10 —Å–æ–æ–±—â–µ–Ω–∏–π –∏—Å—Ç–æ—Ä–∏—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–∂–∏–º–∞–µ—Ç—Å—è –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤!\n\n'
        '–ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ –≤–æ–ø—Ä–æ—Å, –∏ —è –æ—Ç–≤–µ—á—É —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏ DeepSeek Chat!'
    )
    update.message.reply_text(help_text)

def stats_command(update: Update, context: CallbackContext) -> None:
    """Show token usage statistics."""
    if 'token_stats' not in context.user_data or context.user_data['token_stats']['total_requests'] == 0:
        update.message.reply_text('üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—É—Å—Ç–∞. –û—Ç–ø—Ä–∞–≤—å—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –Ω–∞—á–∞–ª–∞.')
        return

    stats = context.user_data['token_stats']

    # Calculate averages
    avg_total = stats['total_tokens'] / stats['total_requests']
    avg_prompt = stats['total_prompt_tokens'] / stats['total_requests']
    avg_completion = stats['total_completion_tokens'] / stats['total_requests']

    stats_text = (
        f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤\n"
        f"{'=' * 35}\n\n"
        f"–í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {stats['total_requests']}\n\n"
        f"–û–±—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:\n"
        f"‚Ä¢ –í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤: {stats['total_tokens']}\n"
        f"‚Ä¢ –¢–æ–∫–µ–Ω–æ–≤ –≤ –∑–∞–ø—Ä–æ—Å–∞—Ö: {stats['total_prompt_tokens']}\n"
        f"‚Ä¢ –¢–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–∞—Ö: {stats['total_completion_tokens']}\n\n"
        f"–°—Ä–µ–¥–Ω–µ–µ –Ω–∞ –∑–∞–ø—Ä–æ—Å:\n"
        f"‚Ä¢ –í—Å–µ–≥–æ: {avg_total:.1f} —Ç–æ–∫–µ–Ω–æ–≤\n"
        f"‚Ä¢ –ó–∞–ø—Ä–æ—Å: {avg_prompt:.1f} —Ç–æ–∫–µ–Ω–æ–≤\n"
        f"‚Ä¢ –û—Ç–≤–µ—Ç: {avg_completion:.1f} —Ç–æ–∫–µ–Ω–æ–≤\n"
    )

    # Show compression statistics
    if 'compression_stats' in context.user_data and context.user_data['compression_stats']['total_compressions'] > 0:
        comp_stats = context.user_data['compression_stats']
        stats_text += f"\n{'=' * 35}\n"
        stats_text += "üóúÔ∏è –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∂–∞—Ç–∏—è:\n\n"
        stats_text += f"‚Ä¢ –í—Å–µ–≥–æ —Å–∂–∞—Ç–∏–π: {comp_stats['total_compressions']}\n"
        stats_text += f"‚Ä¢ –°–æ–æ–±—â–µ–Ω–∏–π —Å–∂–∞—Ç–æ: {comp_stats['messages_compressed']}\n"
        stats_text += f"‚Ä¢ –¢–æ–∫–µ–Ω–æ–≤ —Å—ç–∫–æ–Ω–æ–º–ª–µ–Ω–æ: ~{comp_stats['tokens_saved']}\n"

    # Show last 5 requests
    if stats['requests_history']:
        stats_text += f"\n{'=' * 35}\n"
        stats_text += f"–ü–æ—Å–ª–µ–¥–Ω–∏–µ {min(5, len(stats['requests_history']))} –∑–∞–ø—Ä–æ—Å–æ–≤:\n\n"

        for i, req in enumerate(stats['requests_history'][-5:], 1):
            stats_text += (
                f"{i}. {req['timestamp']}\n"
                f"   –î–ª–∏–Ω–∞ –≤–æ–ø—Ä–æ—Å–∞: {req['question_length']} —Å–∏–º–≤–æ–ª–æ–≤\n"
                f"   –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {req['response_length']} —Å–∏–º–≤–æ–ª–æ–≤\n"
                f"   –¢–æ–∫–µ–Ω—ã: {req['tokens']['total_tokens']} "
                f"({req['tokens']['prompt_tokens']}+{req['tokens']['completion_tokens']})\n\n"
            )

    update.message.reply_text(stats_text)

def clear_command(update: Update, context: CallbackContext) -> None:
    """Clear conversation history."""
    if 'conversation_history' in context.user_data:
        context.user_data['conversation_history'] = []
    update.message.reply_text('üóëÔ∏è –ò—Å—Ç–æ—Ä–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –æ—á–∏—â–µ–Ω–∞!')

def compress_command(update: Update, context: CallbackContext) -> None:
    """Manually compress conversation history."""
    if 'conversation_history' not in context.user_data:
        update.message.reply_text('‚ùå –ò—Å—Ç–æ—Ä–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –ø—É—Å—Ç–∞!')
        return

    history = context.user_data['conversation_history']
    non_system_messages = [msg for msg in history if msg.get('role') != 'system']

    if len(non_system_messages) < 2:
        update.message.reply_text('‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è —Å–∂–∞—Ç–∏—è (–º–∏–Ω–∏–º—É–º 2)')
        return

    update.message.reply_text('üóúÔ∏è –°–∂–∏–º–∞—é –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞...')

    compression_result = compress_conversation_history(context, force=True)

    if compression_result.get('compressed'):
        # Reset message counter after manual compression
        old_counter = context.user_data.get('message_counter', 0)
        context.user_data['message_counter'] = 0

        response = (
            f"‚úÖ –ò—Å—Ç–æ—Ä–∏—è —É—Å–ø–µ—à–Ω–æ —Å–∂–∞—Ç–∞!\n\n"
            f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∂–∞—Ç–∏—è:\n"
            f"‚Ä¢ –°–æ–æ–±—â–µ–Ω–∏–π –¥–æ: {compression_result['messages_before']}\n"
            f"‚Ä¢ –°–æ–æ–±—â–µ–Ω–∏–π –ø–æ—Å–ª–µ: {compression_result['messages_after']}\n"
            f"‚Ä¢ –¢–æ–∫–µ–Ω–æ–≤ –¥–æ: ~{compression_result['tokens_before']}\n"
            f"‚Ä¢ –¢–æ–∫–µ–Ω–æ–≤ –ø–æ—Å–ª–µ: ~{compression_result['tokens_after']}\n"
            f"‚Ä¢ –°—ç–∫–æ–Ω–æ–º–ª–µ–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: ~{compression_result['tokens_saved']}\n"
            f"‚Ä¢ –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∂–∞—Ç–∏—è: {compression_result['compression_ratio']}%\n"
            f"‚Ä¢ –≠–∫–æ–Ω–æ–º–∏—è: {100 - compression_result['compression_ratio']:.0f}%\n\n"
            f"üîÑ –°—á—ë—Ç—á–∏–∫ —Å–æ–æ–±—â–µ–Ω–∏–π —Å–±—Ä–æ—à–µ–Ω (–±—ã–ª–æ: #{old_counter})"
        )
        update.message.reply_text(response)
    else:
        update.message.reply_text(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∂–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é: {compression_result.get('reason', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")

def ask_question(update: Update, context: CallbackContext) -> None:
    """Send the user's question to DeepSeek API and return the response."""
    if update.message is None or update.message.text is None:
        update.message.reply_text("Sorry, I couldn't process that message.")
        return

    user_question = update.message.text

    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å chat_id –ø—Ä–∏ –ø–µ—Ä–≤–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏
    if 'admin_chat_id' not in context.bot_data:
        context.bot_data['admin_chat_id'] = update.message.chat_id
        logger.info(f"Saved admin_chat_id: {update.message.chat_id}")

    # Initialize conversation history and current date in context if it doesn't exist
    if 'conversation_history' not in context.user_data:
        context.user_data['conversation_history'] = []

    # Initialize token statistics
    if 'token_stats' not in context.user_data:
        context.user_data['token_stats'] = {
            'total_requests': 0,
            'total_tokens': 0,
            'total_prompt_tokens': 0,
            'total_completion_tokens': 0,
            'requests_history': []
        }

    # Initialize message counter
    if 'message_counter' not in context.user_data:
        context.user_data['message_counter'] = 0

    # Increment message counter
    context.user_data['message_counter'] += 1
    current_message_num = context.user_data['message_counter']

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –ø—Ä–æ –∑–∞–¥–∞—á–∏ –∏–∑ Tracker
    keywords = ["–∑–∞–¥–∞—á", "task", "tracker", "issue", "—Ç—Ä–µ–∫–µ—Ä"]
    message_lower = user_question.lower()

    logger.info(f"Checking message for tracker keywords: '{message_lower}'")
    keyword_found = any(keyword in message_lower for keyword in keywords)
    logger.info(f"Keyword found: {keyword_found}")

    if keyword_found:
        logger.info("Detected tracker-related question, executing pipeline...")
        update.message.reply_text("üîÑ –ó–∞–ø—É—Å–∫–∞—é –∞–Ω–∞–ª–∏–∑ –∑–∞–¥–∞—á –∏–∑ Yandex Tracker...")

        try:
            # –í—ã–ø–æ–ª–Ω–∏—Ç—å –ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω
            pipeline_result = execute_tasks_pipeline()

            if not pipeline_result["success"]:
                # –û—à–∏–±–∫–∞ –≤ –ø–∞–π–ø–ª–∞–π–Ω–µ
                error_msg = f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –Ω–∞ —ç—Ç–∞–ø–µ '{pipeline_result['step']}': {pipeline_result.get('error', 'Unknown error')}"
                update.message.reply_text(error_msg)

                # –ï—Å–ª–∏ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∑–∞–¥–∞—á–∏, –¥–æ–±–∞–≤–∏–º –∏—Ö –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
                if pipeline_result.get("tasks_json"):
                    tracker_context = {
                        "role": "system",
                        "content": f"–°–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á –∏–∑ Yandex Tracker:\n{pipeline_result['tasks_json']}"
                    }
                    context.user_data['conversation_history'].insert(0, tracker_context)
            else:
                # –ü–∞–π–ø–ª–∞–π–Ω —É—Å–ø–µ—à–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω
                update.message.reply_text("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω!")

                # –ü–æ–∫–∞–∑–∞—Ç—å —Ä—É—Å—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
                if pipeline_result.get("analysis"):
                    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏, –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç –¥–ª–∏–Ω–Ω—ã–π (Telegram limit 4096 chars)
                    analysis_text = f"üìä –ê–Ω–∞–ª–∏–∑ –∑–∞–¥–∞—á:\n\n{pipeline_result['analysis']}"
                    if len(analysis_text) > 4000:
                        update.message.reply_text(analysis_text[:4000])
                        update.message.reply_text(analysis_text[4000:])
                    else:
                        update.message.reply_text(analysis_text)

                # –ü–æ–∫–∞–∑–∞—Ç—å –ø–µ—Ä–µ–≤–æ–¥ –Ω–∞ —ç—Å–ø–µ—Ä–∞–Ω—Ç–æ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
                if pipeline_result.get("translation"):
                    translation_text = f"üåê Traduko en Esperanton:\n\n{pipeline_result['translation']}"
                    if len(translation_text) > 4000:
                        update.message.reply_text(translation_text[:4000])
                        update.message.reply_text(translation_text[4000:])
                    else:
                        update.message.reply_text(translation_text)
                elif pipeline_result.get("error") and "–ø–µ—Ä–µ–≤–æ–¥" in pipeline_result["error"].lower():
                    update.message.reply_text(
                        "‚ö†Ô∏è –ü–µ—Ä–µ–≤–æ–¥ –Ω–∞ —ç—Å–ø–µ—Ä–∞–Ω—Ç–æ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü–æ–∫–∞–∑–∞–Ω —Ä—É—Å—Å–∫–∏–π –≤–∞—Ä–∏–∞–Ω—Ç."
                    )

                # –î–æ–±–∞–≤–∏—Ç—å –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
                context_content = f"–ê–Ω–∞–ª–∏–∑ –∑–∞–¥–∞—á –∏–∑ Yandex Tracker:\n{pipeline_result['analysis']}"
                if pipeline_result.get("translation"):
                    context_content += f"\n\n–ü–µ—Ä–µ–≤–æ–¥ –Ω–∞ —ç—Å–ø–µ—Ä–∞–Ω—Ç–æ:\n{pipeline_result['translation']}"

                tracker_context = {
                    "role": "system",
                    "content": context_content
                }
                context.user_data['conversation_history'].insert(0, tracker_context)

            logger.info("Pipeline execution completed")

        except Exception as e:
            logger.error(f"Error executing pipeline: {e}", exc_info=True)
            update.message.reply_text(
                f"‚ö†Ô∏è –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–¥–∞—á: {str(e)}"
            )

        # –ó–∞–≤–µ—Ä—à–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É - –ø–∞–π–ø–ª–∞–π–Ω —É–∂–µ –≤—ã–¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        return

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –ø—Ä–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
    monitoring_keywords = ["–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥", "health", "—Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–µ—Ä–≤–µ—Ä–∞", "–º–µ—Ç—Ä–∏–∫–∏", "monitoring", "—Å—Ç–∞—Ç—É—Å —Å–µ—Ä–≤–µ—Ä–∞"]
    monitoring_keyword_found = any(keyword in message_lower for keyword in monitoring_keywords)

    if monitoring_keyword_found:
        logger.info("Detected monitoring-related question, collecting host metrics...")
        update.message.reply_text("üîÑ –°–æ–±–∏—Ä–∞—é –º–µ—Ç—Ä–∏–∫–∏ —Ö–æ—Å—Ç–∞...")

        try:
            # –í—ã–∑–≤–∞—Ç—å MCP tool –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫
            monitoring_result_json = call_mcp_tool_sync_on_server(
                MCP_SERVER_URL,
                "get-host-metrics"
            )

            if not monitoring_result_json:
                update.message.reply_text("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏. MCP —Å–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.")
                return

            # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            try:
                metrics = json.loads(monitoring_result_json)

                if metrics.get("success"):
                    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫—Ä–∞—Å–∏–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
                    cpu = metrics.get("cpu", {})
                    memory = metrics.get("memory", {})
                    disk = metrics.get("disk", {})
                    uptime = metrics.get("uptime", {})
                    system = metrics.get("system", {})
                    timestamp = metrics.get("timestamp", "")

                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —ç–º–æ–¥–∑–∏ –¥–ª—è —É—Ä–æ–≤–Ω—è –∑–∞–≥—Ä—É–∑–∫–∏
                    cpu_emoji = "üü¢" if cpu.get("percent", 0) < 50 else "üü°" if cpu.get("percent", 0) < 80 else "üî¥"
                    mem_emoji = "üü¢" if memory.get("percent", 0) < 50 else "üü°" if memory.get("percent", 0) < 80 else "üî¥"
                    disk_emoji = "üü¢" if disk.get("percent", 0) < 50 else "üü°" if disk.get("percent", 0) < 80 else "üî¥"

                    metrics_msg = (
                        f"üìä –ú–µ—Ç—Ä–∏–∫–∏ —Ö–æ—Å—Ç–∞\n"
                        f"{'=' * 30}\n"
                        f"üïê {timestamp}\n\n"
                        f"{cpu_emoji} CPU:\n"
                        f"  ‚Ä¢ –ó–∞–≥—Ä—É–∑–∫–∞: {cpu.get('percent', 0):.1f}%\n"
                        f"  ‚Ä¢ –Ø–¥—Ä–∞: {cpu.get('cores', 'N/A')}\n"
                        f"  ‚Ä¢ –ß–∞—Å—Ç–æ—Ç–∞: {cpu.get('frequency_mhz', 0)} MHz\n\n"
                        f"{mem_emoji} –ü–∞–º—è—Ç—å:\n"
                        f"  ‚Ä¢ –ó–∞–≥—Ä—É–∑–∫–∞: {memory.get('percent', 0):.1f}%\n"
                        f"  ‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {memory.get('used_gb', 0):.2f} GB\n"
                        f"  ‚Ä¢ –í—Å–µ–≥–æ: {memory.get('total_gb', 0):.2f} GB\n\n"
                        f"{disk_emoji} –î–∏—Å–∫:\n"
                        f"  ‚Ä¢ –ó–∞–≥—Ä—É–∑–∫–∞: {disk.get('percent', 0):.1f}%\n"
                        f"  ‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {disk.get('used_gb', 0):.2f} GB\n"
                        f"  ‚Ä¢ –í—Å–µ–≥–æ: {disk.get('total_gb', 0):.2f} GB\n\n"
                        f"‚è±Ô∏è Uptime: {uptime.get('formatted', 'N/A')}\n"
                        f"üîÑ –ó–∞–ø—É—Å–∫: {uptime.get('boot_time', 'N/A')}\n\n"
                        f"üíª –°–∏—Å—Ç–µ–º–∞:\n"
                        f"  ‚Ä¢ –•–æ—Å—Ç: {system.get('hostname', 'N/A')}\n"
                        f"  ‚Ä¢ –û–°: {system.get('platform', 'N/A')}\n"
                        f"  ‚Ä¢ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {system.get('architecture', 'N/A')}\n"
                        f"  ‚Ä¢ IP: {system.get('ip_address', 'N/A')}\n"
                        f"  ‚Ä¢ –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {system.get('temperature', 'N/A')}"
                    )
                    update.message.reply_text(metrics_msg)
                else:
                    # –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –º–µ—Ç—Ä–∏–∫
                    error = metrics.get("error", "Unknown error")
                    update.message.reply_text(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –º–µ—Ç—Ä–∏–∫: {error}")

            except json.JSONDecodeError:
                # –ù–µ JSON –æ—Ç–≤–µ—Ç
                update.message.reply_text(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {monitoring_result_json[:500]}")

            logger.info("Monitoring request completed")
            return

        except Exception as e:
            logger.error(f"Error getting metrics: {e}", exc_info=True)
            update.message.reply_text(
                f"‚ö†Ô∏è –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –º–µ—Ç—Ä–∏–∫: {str(e)}"
            )
            return

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø—Ä–æ API (–î–µ–Ω—å 17: RAG)
    api_keywords = ["api", "endpoint", "sim", "esim", "inventory", "pond mobile", "msisdn",
                    "transfer", "webhook", "country", "countries", "group", "whitelist"]
    api_keyword_found = any(keyword in message_lower for keyword in api_keywords)

    if api_keyword_found and RAG_AVAILABLE:
        logger.info("Detected API-related question, using RAG...")
        update.message.reply_text("üîç –ò—â—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ Pond Mobile API...")

        try:
            # –í—ã–ø–æ–ª–Ω–∏—Ç—å RAG-–∑–∞–ø—Ä–æ—Å —Å —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ–º
            rag_result = handle_rag_query(user_question)

            if not rag_result["success"]:
                error_msg = f"‚ö†Ô∏è –û—à–∏–±–∫–∞ RAG: {rag_result.get('error', 'Unknown error')}"
                update.message.reply_text(error_msg)
                # –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Å –æ–±—ã—á–Ω—ã–º –æ—Ç–≤–µ—Ç–æ–º
            else:
                # –ü–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã 3-—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                update.message.reply_text(
                    "‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω! –°—Ä–∞–≤–Ω–∏–≤–∞—é 3 –≤–∞—Ä–∏–∞–Ω—Ç–∞:\n"
                    "1Ô∏è‚É£ –ë–µ–∑ RAG (baseline)\n"
                    "2Ô∏è‚É£ –° RAG –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏\n"
                    "3Ô∏è‚É£ –° RAG —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π"
                )

                # 1. –û—Ç–≤–µ—Ç –ë–ï–ó RAG
                without_rag_msg = (
                    "1Ô∏è‚É£ –û–¢–í–ï–¢ –ë–ï–ó RAG (baseline):\n\n"
                    f"{rag_result['answer_without_rag']}\n\n"
                    f"üìä –¢–æ–∫–µ–Ω–æ–≤: {rag_result['tokens_without_rag']['total_tokens']}"
                )
                if len(without_rag_msg) > 4000:
                    update.message.reply_text(without_rag_msg[:4000])
                    update.message.reply_text(without_rag_msg[4000:])
                else:
                    update.message.reply_text(without_rag_msg)

                # 2. –° RAG –ë–ï–ó –§–ò–õ–¨–¢–†–ê–¶–ò–ò
                if rag_result["relevant_chunks_unfiltered"]:
                    chunks_unfiltered = rag_result["relevant_chunks_unfiltered"]
                    unfiltered_msg = "2Ô∏è‚É£ –° RAG –ë–ï–ó –§–ò–õ–¨–¢–†–ê–¶–ò–ò\n\nüìö –ù–∞–π–¥–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã:\n"
                    for i, chunk in enumerate(chunks_unfiltered, 1):
                        unfiltered_msg += (
                            f"\n{i}. {chunk['method']} {chunk['endpoint_path']}\n"
                            f"   –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {chunk['similarity']:.1%}\n"
                            f"   –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {chunk['tag']}\n"
                        )

                    if rag_result["answer_with_rag_unfiltered"]:
                        unfiltered_msg += f"\n\nüí¨ –û—Ç–≤–µ—Ç:\n{rag_result['answer_with_rag_unfiltered']}\n\n"
                        unfiltered_msg += f"üìä –¢–æ–∫–µ–Ω–æ–≤: {rag_result['tokens_with_rag_unfiltered']['total_tokens']}"

                    if len(unfiltered_msg) > 4000:
                        update.message.reply_text(unfiltered_msg[:4000])
                        update.message.reply_text(unfiltered_msg[4000:])
                    else:
                        update.message.reply_text(unfiltered_msg)

                # 3. –° RAG –° –§–ò–õ–¨–¢–†–ê–¶–ò–ï–ô
                filter_stats = rag_result["filter_stats"]
                chunks_filtered = rag_result["relevant_chunks_filtered"]

                filtered_msg = "3Ô∏è‚É£ –° RAG –° –§–ò–õ–¨–¢–†–ê–¶–ò–ï–ô (hybrid)\n\n"
                filtered_msg += "üîç –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏:\n"
                filtered_msg += f"‚Ä¢ –î–æ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {filter_stats.get('input_count', 0)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n"
                filtered_msg += f"‚Ä¢ –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {filter_stats.get('output_count', 0)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n"
                filtered_msg += f"‚Ä¢ –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ (—Å—Ç—Ä–æ–≥–∏–π –ø–æ—Ä–æ–≥ ‚â•50%): {filter_stats.get('filtered_strict', 0)}\n"
                filtered_msg += f"‚Ä¢ –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ (–∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π ‚â•85% –æ—Ç —Ç–æ–ø–∞): {filter_stats.get('filtered_adaptive', 0)}\n"
                filtered_msg += f"‚Ä¢ –¢–æ–ø —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {filter_stats.get('top_score', 0):.1%}\n"
                if filter_stats.get('adaptive_cutoff'):
                    filtered_msg += f"‚Ä¢ –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥: {filter_stats['adaptive_cutoff']:.1%}\n"

                filtered_msg += "\nüìö –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã:\n"
                for i, chunk in enumerate(chunks_filtered, 1):
                    filtered_msg += (
                        f"\n{i}. {chunk['method']} {chunk['endpoint_path']}\n"
                        f"   –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {chunk['similarity']:.1%}\n"
                        f"   –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {chunk['tag']}\n"
                    )

                if rag_result["answer_with_rag_filtered"]:
                    filtered_msg += f"\n\nüí¨ –û—Ç–≤–µ—Ç:\n{rag_result['answer_with_rag_filtered']}\n\n"
                    filtered_msg += f"üìä –¢–æ–∫–µ–Ω–æ–≤: {rag_result['tokens_with_rag_filtered']['total_tokens']}"

                if len(filtered_msg) > 4000:
                    update.message.reply_text(filtered_msg[:4000])
                    update.message.reply_text(filtered_msg[4000:])
                else:
                    update.message.reply_text(filtered_msg)

                # 4. –ò—Ç–æ–≥–æ–≤–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
                comparison_msg = (
                    "üìä –ò–¢–û–ì–û–í–û–ï –°–†–ê–í–ù–ï–ù–ò–ï:\n\n"
                    "–¢–æ–∫–µ–Ω—ã:\n"
                    f"‚Ä¢ –ë–µ–∑ RAG: {rag_result['tokens_without_rag']['total_tokens']}\n"
                    f"‚Ä¢ –° RAG (–±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞): {rag_result['tokens_with_rag_unfiltered']['total_tokens']}\n"
                    f"‚Ä¢ –° RAG (—Å —Ñ–∏–ª—å—Ç—Ä–æ–º): {rag_result['tokens_with_rag_filtered']['total_tokens']}\n\n"
                    "–î–æ–∫—É–º–µ–Ω—Ç—ã:\n"
                    f"‚Ä¢ –ë–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞: {len(rag_result['relevant_chunks_unfiltered'])}\n"
                    f"‚Ä¢ –° —Ñ–∏–ª—å—Ç—Ä–æ–º: {len(rag_result['relevant_chunks_filtered'])}\n\n"
                    "üí° –í—ã–≤–æ–¥:\n"
                    "–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —É–±–∏—Ä–∞–µ—Ç –Ω–∏–∑–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ —É–ª—É—á—à–∞–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å RAG.\n"
                    "–ì–∏–±—Ä–∏–¥–Ω—ã–π —Ä–µ–∂–∏–º —Å–æ—á–µ—Ç–∞–µ—Ç —Å—Ç—Ä–æ–≥–∏–π –ø–æ—Ä–æ–≥ (‚â•50%) –∏ –∞–¥–∞–ø—Ç–∏–≤–Ω—É—é —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é (‚â•85% –æ—Ç —Ç–æ–ø–∞)."
                )
                update.message.reply_text(comparison_msg)

                logger.info("RAG comparison completed successfully")
                return

        except Exception as e:
            logger.error(f"Error in RAG processing: {e}", exc_info=True)
            update.message.reply_text(
                f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ RAG-–∑–∞–ø—Ä–æ—Å–∞: {str(e)}\n"
                "–ü—Ä–æ–¥–æ–ª–∂–∞—é —Å –æ–±—ã—á–Ω—ã–º –æ—Ç–≤–µ—Ç–æ–º..."
            )

    # Add user message to conversation history
    context.user_data['conversation_history'].append({
        "role": "user",
        "content": user_question
    })

    # Auto-compress every 10 messages (excluding system messages)
    non_system_messages = [msg for msg in context.user_data['conversation_history'] if msg.get('role') != 'system']
    if len(non_system_messages) >= 10:
        compression_result = compress_conversation_history(context)
        if compression_result.get('compressed'):
            # Reset message counter after compression
            context.user_data['message_counter'] = 0
            update.message.reply_text(
                f"üóúÔ∏è –ê–≤—Ç–æ—Å–∂–∞—Ç–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ (–ø–æ—Å–ª–µ —Å–æ–æ–±—â–µ–Ω–∏—è #{current_message_num}):\n"
                f"‚Ä¢ –°–∂–∞—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {compression_result['messages_before']}\n"
                f"‚Ä¢ –¢–æ–∫–µ–Ω–æ–≤ –±—ã–ª–æ: ~{compression_result['tokens_before']}\n"
                f"‚Ä¢ –¢–æ–∫–µ–Ω–æ–≤ —Å—Ç–∞–ª–æ: ~{compression_result['tokens_after']}\n"
                f"‚Ä¢ –≠–∫–æ–Ω–æ–º–∏—è: ~{compression_result['tokens_saved']} —Ç–æ–∫–µ–Ω–æ–≤ ({100 - compression_result['compression_ratio']:.0f}%)\n"
                f"‚Ä¢ –°—á—ë—Ç—á–∏–∫ —Å–æ–æ–±—â–µ–Ω–∏–π —Å–±—Ä–æ—à–µ–Ω!"
            )

    # Estimate input length for warning
    estimated_input_chars = sum(len(msg['content']) for msg in context.user_data['conversation_history'])
    estimated_input_tokens = estimated_input_chars // 4  # Rough estimate: 1 token ‚âà 4 chars

    # Warn if input is very long
    if estimated_input_tokens > 7000:
        update.message.reply_text(
            "‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: –û—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å!\n"
            f"–ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ {estimated_input_tokens} —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∏—Å—Ç–æ—Ä–∏–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞.\n"
            "–ú–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤–µ—Å—å –∫–æ–Ω—Ç–µ–∫—Å—Ç."
        )

    # Call DeepSeek API with conversation history
    gpt_response, token_usage = call_deepseek_api(context.user_data['conversation_history'])

    # Add assistant response to conversation history
    context.user_data['conversation_history'].append({
        "role": "assistant",
        "content": gpt_response
    })

    # Update token statistics
    context.user_data['token_stats']['total_requests'] += 1
    context.user_data['token_stats']['total_tokens'] += token_usage['total_tokens']
    context.user_data['token_stats']['total_prompt_tokens'] += token_usage['prompt_tokens']
    context.user_data['token_stats']['total_completion_tokens'] += token_usage['completion_tokens']

    # Add to request history (keep last 20 requests)
    from datetime import datetime
    context.user_data['token_stats']['requests_history'].append({
        'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        'question_length': len(user_question),
        'response_length': len(gpt_response),
        'tokens': token_usage
    })
    if len(context.user_data['token_stats']['requests_history']) > 20:
        context.user_data['token_stats']['requests_history'].pop(0)

    # Format response with token information
    token_info = (
        f"\n\nüìä –°–æ–æ–±—â–µ–Ω–∏–µ #{current_message_num} | –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤:\n"
        f"‚Ä¢ –ó–∞–ø—Ä–æ—Å: {token_usage['prompt_tokens']}\n"
        f"‚Ä¢ –û—Ç–≤–µ—Ç: {token_usage['completion_tokens']}\n"
        f"‚Ä¢ –í—Å–µ–≥–æ: {token_usage['total_tokens']}"
    )

    # Send the response directly to the user with token info
    full_response = gpt_response + token_info
    update.message.reply_text(full_response)

def create_conversation_summary(messages) -> str:
    """Create a summary of conversation history using DeepSeek API.

    Args:
        messages: List of conversation messages

    Returns:
        str: Summary of the conversation
    """
    if not messages:
        return ""

    # Prepare prompt for summarization
    conversation_text = "\n".join([
        f"{msg['role'].upper()}: {msg['content']}"
        for msg in messages
    ])

    summary_prompt = f"""–°–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞.
–°–æ—Ö—Ä–∞–Ω–∏ –í–°–Æ –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, —Ñ–∞–∫—Ç—ã, –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –≤—ã–≤–æ–¥—ã.
–†–µ–∑—é–º–µ –¥–æ–ª–∂–Ω–æ –ø–æ–∑–≤–æ–ª–∏—Ç—å –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.

–î–∏–∞–ª–æ–≥:
{conversation_text}

–ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ (–Ω–∞ —Ä—É—Å—Å–∫–æ–º):"""

    summary_messages = [
        {"role": "system", "content": "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–∑–¥–∞—ë—Ç –∫—Ä–∞—Ç–∫–∏–µ —Ä–µ–∑—é–º–µ –¥–∏–∞–ª–æ–≥–æ–≤, —Å–æ—Ö—Ä–∞–Ω—è—è –≤—Å—é –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é."},
        {"role": "user", "content": summary_prompt}
    ]

    try:
        response_text, _ = call_deepseek_api(summary_messages)
        return response_text
    except Exception as e:
        logger.error(f"Error creating summary: {e}")
        # Fallback: create simple summary
        return f"–û–±—Å—É–∂–¥–∞–ª–æ—Å—å {len(messages)} —Å–æ–æ–±—â–µ–Ω–∏–π. –¢–µ–º—ã: {', '.join(set([msg['content'][:30] + '...' for msg in messages[:3]]))}"

def compress_conversation_history(context: CallbackContext, force: bool = False) -> dict:
    """Compress conversation history by creating a summary.

    Args:
        context: Telegram context with user_data
        force: Force compression even if threshold not reached

    Returns:
        dict: Compression statistics
    """
    if 'conversation_history' not in context.user_data:
        return {'compressed': False, 'reason': 'No history'}

    history = context.user_data['conversation_history']

    # Skip if history is too short (unless forced)
    if len(history) < 10 and not force:
        return {'compressed': False, 'reason': 'History too short', 'messages': len(history)}

    # Calculate tokens before compression
    chars_before = sum(len(msg['content']) for msg in history)
    tokens_before = chars_before // 4

    # Create summary of all messages except system messages
    messages_to_summarize = [msg for msg in history if msg.get('role') != 'system']

    if not messages_to_summarize:
        return {'compressed': False, 'reason': 'No messages to compress'}

    logger.info(f"Compressing {len(messages_to_summarize)} messages...")
    summary = create_conversation_summary(messages_to_summarize)

    # Replace history with summary
    context.user_data['conversation_history'] = [
        {
            "role": "system",
            "content": f"–ü—Ä–µ–¥—ã–¥—É—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ (—Ä–µ–∑—é–º–µ {len(messages_to_summarize)} —Å–æ–æ–±—â–µ–Ω–∏–π):\n{summary}"
        }
    ]

    # Calculate tokens after compression
    chars_after = len(summary)
    tokens_after = chars_after // 4

    # Update compression statistics
    if 'compression_stats' not in context.user_data:
        context.user_data['compression_stats'] = {
            'total_compressions': 0,
            'tokens_saved': 0,
            'messages_compressed': 0
        }

    context.user_data['compression_stats']['total_compressions'] += 1
    context.user_data['compression_stats']['tokens_saved'] += (tokens_before - tokens_after)
    context.user_data['compression_stats']['messages_compressed'] += len(messages_to_summarize)

    return {
        'compressed': True,
        'messages_before': len(messages_to_summarize),
        'messages_after': 1,
        'tokens_before': tokens_before,
        'tokens_after': tokens_after,
        'tokens_saved': tokens_before - tokens_after,
        'compression_ratio': round(tokens_after / tokens_before * 100, 1) if tokens_before > 0 else 0
    }

def call_deepseek_api(messages) -> tuple:
    """Call DeepSeek API and return the response with token usage.

    Returns:
        tuple: (response_text, token_usage_dict) where token_usage_dict contains:
            - total_tokens: total tokens used
            - prompt_tokens: tokens in the prompt
            - completion_tokens: tokens in the completion
    """
    if not DEEPSEEK_API_KEY:
        return ("DeepSeek API key not configured. Please check your environment variables.",
                {"total_tokens": 0, "prompt_tokens": 0, "completion_tokens": 0})

    headers = {
        'Authorization': f'Bearer {DEEPSEEK_API_KEY}',
        'Content-Type': 'application/json'
    }

    # Add system message if not present
    formatted_messages = []
    if not any(msg.get('role') == 'system' for msg in messages):
        formatted_messages.append({
            "role": "system",
            "content": "–¢—ã ‚Äî –ø–æ–ª–µ–∑–Ω—ã–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç–æ—á–Ω–æ –∏ –ø–æ–ª–µ–∑–Ω–æ."
        })

    # Add conversation history
    formatted_messages.extend(messages)

    payload = {
        "model": MODEL_NAME,
        "messages": formatted_messages,
        "temperature": 0.7,
        "max_tokens": 2000
    }

    try:
        response = requests.post(DEEPSEEK_API_URL, headers=headers, data=json.dumps(payload))
        response.raise_for_status()
        result = response.json()

        # Extract response text
        response_text = result['choices'][0]['message']['content']

        # Extract token usage from response
        usage = result.get('usage', {})

        # Get token counts
        prompt_tokens = usage.get('prompt_tokens', 0)
        completion_tokens = usage.get('completion_tokens', 0)
        total_tokens = usage.get('total_tokens', 0)

        token_usage = {
            'total_tokens': total_tokens,
            'prompt_tokens': prompt_tokens,
            'completion_tokens': completion_tokens
        }

        logger.info(f"Token usage: Total={total_tokens}, Prompt={prompt_tokens}, Completion={completion_tokens}")

        return (response_text, token_usage)
    except Exception as e:
        logger.error(f"Error calling DeepSeek API: {e}")
        if hasattr(e, 'response') and e.response is not None:
            logger.error(f"Response status: {e.response.status_code}")
            logger.error(f"Response body: {e.response.text}")
        error_msg = f"Sorry, I encountered an error while processing your request: {str(e)}"
        return (error_msg, {"total_tokens": 0, "prompt_tokens": 0, "completion_tokens": 0})


def analyze_tasks_order(tasks_json: str) -> str:
    """
    –ê–Ω–∞–ª–∏–∑ –∑–∞–¥–∞—á –∏ —Å–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —á–µ—Ä–µ–∑ DeepSeek.

    Args:
        tasks_json: JSON —Å—Ç—Ä–æ–∫–∞ —Å –∑–∞–¥–∞—á–∞–º–∏ –∏–∑ Yandex Tracker

    Returns:
        –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç—á—ë—Ç —Å –∞–Ω–∞–ª–∏–∑–æ–º –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–º –ø–æ—Ä—è–¥–∫–æ–º –∑–∞–¥–∞—á
    """
    analysis_prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π —Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á –∏–∑ Yandex Tracker.

–ó–∞–¥–∞—á–∏:
{tasks_json}

–¢–≤–æ—è –∑–∞–¥–∞—á–∞:
1. –û–ø—Ä–µ–¥–µ–ª–∏ –ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø–æ—Ä—è–¥–æ–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á
2. –ù–∞–π–¥–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–£—Ç–æ—á–Ω–∏—Ç—å –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å" –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø–µ—Ä–µ–¥ "–ó–∞–∫–∞–∑–∞—Ç—å")
3. –£—á—Ç–∏ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –∏ —Å—Ç–∞—Ç—É—Å—ã –∑–∞–¥–∞—á
4. –°–æ–∑–¥–∞–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç—á—ë—Ç —Å —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–º –ø–æ—Ä—è–¥–∫–æ–º

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
# –ê–Ω–∞–ª–∏–∑ –∑–∞–¥–∞—á –∏–∑ Yandex Tracker

## –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

1. [KEY] - –ù–∞–∑–≤–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏
   –ü—Ä–∏—á–∏–Ω–∞: [–æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø–æ—á–µ–º—É —ç—Ç–∞ –∑–∞–¥–∞—á–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ø–µ—Ä–≤–æ–π]
   –°—Ç–∞—Ç—É—Å: [—Ç–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å]

2. [KEY] - –ù–∞–∑–≤–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏
   –ü—Ä–∏—á–∏–Ω–∞: [–æ–±—ä—è—Å–Ω–µ–Ω–∏–µ]
   –°—Ç–∞—Ç—É—Å: [—Ç–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å]

[–∏ —Ç–∞–∫ –¥–∞–ª–µ–µ...]

## –í—ã–≤–æ–¥—ã:
[–ö—Ä–∞—Ç–∫–∏–µ –≤—ã–≤–æ–¥—ã –æ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è—Ö –∏ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞—Ö]
"""

    messages = [
        {
            "role": "system",
            "content": "–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—é –ø—Ä–æ–µ–∫—Ç–∞–º–∏. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å –∑–∞–¥–∞—á–∏ –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—à—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ –∏—Ö –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è."
        },
        {
            "role": "user",
            "content": analysis_prompt
        }
    ]

    try:
        logger.info("Analyzing tasks with DeepSeek...")
        response_text, token_usage = call_deepseek_api(messages)
        logger.info(f"Task analysis completed. Tokens used: {token_usage['total_tokens']}")
        return response_text
    except Exception as e:
        logger.error(f"Error analyzing tasks: {e}")
        return f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–¥–∞—á: {str(e)}"


# MCP Client functions
async def call_mcp_tool(tool_name: str, arguments: dict = None):
    """–í—ã–∑–æ–≤ MCP tool —á–µ—Ä–µ–∑ WebSocket –∏ –ø–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞."""
    try:
        logger.info(f"Connecting to MCP server at {MCP_SERVER_URL}")
        async with websocket_client(MCP_SERVER_URL) as (read, write):
            logger.info("WebSocket connection established")
            async with ClientSession(read, write) as session:
                logger.info("MCP session created")

                # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å timeout
                await asyncio.wait_for(session.initialize(), timeout=10.0)
                logger.info("Session initialized")

                # –í—ã–∑–æ–≤ tool —Å timeout
                logger.info(f"Calling tool: {tool_name}")
                result = await asyncio.wait_for(
                    session.call_tool(tool_name, arguments or {}),
                    timeout=15.0
                )
                logger.info(f"Tool call completed")

                # –ò–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                if result.content and len(result.content) > 0:
                    logger.info(f"Result content: {len(result.content[0].text)} chars")
                    return result.content[0].text
                else:
                    logger.warning("No content in result")
                return None
    except asyncio.TimeoutError:
        logger.error(f"Timeout calling MCP tool: {tool_name}")
        return None
    except Exception as e:
        logger.error(f"Error calling MCP tool: {e}", exc_info=True)
        return None


def call_mcp_tool_sync(tool_name: str, arguments: dict = None):
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –≤—ã–∑–æ–≤–∞ async MCP tool."""
    loop = asyncio.new_event_loop()
    try:
        return loop.run_until_complete(call_mcp_tool(tool_name, arguments))
    finally:
        loop.close()


def call_mcp_tool_sync_on_server(server_url: str, tool_name: str, arguments: dict = None):
    """
    –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –≤—ã–∑–æ–≤–∞ MCP tool –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º —Å–µ—Ä–≤–µ—Ä–µ.

    Args:
        server_url: WebSocket URL –úCP —Å–µ—Ä–≤–µ—Ä–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, ws://localhost:8081/mcp)
        tool_name: –ò–º—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –¥–ª—è –≤—ã–∑–æ–≤–∞
        arguments: –ê—Ä–≥—É–º–µ–Ω—Ç—ã –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

    Returns:
        –¢–µ–∫—Å—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    async def call_tool_async():
        try:
            logger.info(f"Connecting to MCP server at {server_url}")
            async with websocket_client(server_url) as (read, write):
                logger.info("WebSocket connection established")
                async with ClientSession(read, write) as session:
                    logger.info("MCP session created")

                    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å timeout
                    await asyncio.wait_for(session.initialize(), timeout=10.0)
                    logger.info("Session initialized")

                    # –í—ã–∑–æ–≤ tool —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º timeout –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞
                    logger.info(f"Calling tool: {tool_name}")
                    result = await asyncio.wait_for(
                        session.call_tool(tool_name, arguments or {}),
                        timeout=30.0  # –î–ª–∏–Ω–Ω—ã–π timeout –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞
                    )
                    logger.info(f"Tool call completed")

                    if result.content and len(result.content) > 0:
                        return result.content[0].text
                    else:
                        logger.warning("No content in result")
                    return None
        except asyncio.TimeoutError:
            logger.error(f"Timeout calling {tool_name} on {server_url}")
            return None
        except Exception as e:
            logger.error(f"Error calling {tool_name} on {server_url}: {e}", exc_info=True)
            return None

    loop = asyncio.new_event_loop()
    try:
        return loop.run_until_complete(call_tool_async())
    finally:
        loop.close()


def execute_tasks_pipeline() -> dict:
    """
    –í—ã–ø–æ–ª–Ω–∏—Ç—å –ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω: –ü–æ–ª—É—á–∏—Ç—å –∑–∞–¥–∞—á–∏ -> –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å -> –ü–µ—Ä–µ–≤–µ—Å—Ç–∏.

    Returns:
        dict —Å–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π:
        {
            "success": bool,
            "step": str,  # –ü–æ—Å–ª–µ–¥–Ω–∏–π —É—Å–ø–µ—à–Ω—ã–π —à–∞–≥
            "tasks_json": str,
            "analysis": str,
            "translation": str,
            "error": str  # –ï—Å–ª–∏ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞
        }
    """
    result = {
        "success": False,
        "step": "none",
        "tasks_json": None,
        "analysis": None,
        "translation": None,
        "error": None
    }

    try:
        # –®–∞–≥ 1: –ü–æ–ª—É—á–∏—Ç—å –∑–∞–¥–∞—á–∏ –∏–∑ Yandex Tracker —á–µ—Ä–µ–∑ MCP Server 1
        logger.info("Pipeline Step 1: Fetching tasks from Yandex Tracker")
        tasks_json = call_mcp_tool_sync_on_server(
            MCP_SERVER_URL,
            "get-tracker-tasks"
        )

        if not tasks_json or "error" in tasks_json.lower():
            result["error"] = "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∑–∞–¥–∞—á–∏ –∏–∑ Yandex Tracker"
            result["step"] = "fetch_tasks"
            return result

        result["tasks_json"] = tasks_json
        result["step"] = "fetch_tasks"
        logger.info(f"Step 1 complete: Retrieved {len(tasks_json)} chars")

        # –®–∞–≥ 2: –ê–Ω–∞–ª–∏–∑ –∑–∞–¥–∞—á —Å –ø–æ–º–æ—â—å—é DeepSeek
        logger.info("Pipeline Step 2: Analyzing tasks with DeepSeek")
        analysis = analyze_tasks_order(tasks_json)

        if not analysis or "–æ—à–∏–±–∫–∞" in analysis.lower()[:100]:
            result["error"] = "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∑–∞–¥–∞—á–∏"
            result["step"] = "analyze_tasks"
            return result

        result["analysis"] = analysis
        result["step"] = "analyze_tasks"
        logger.info(f"Step 2 complete: Analysis {len(analysis)} chars")

        # –®–∞–≥ 3: –ü–µ—Ä–µ–≤–æ–¥ –Ω–∞ —ç—Å–ø–µ—Ä–∞–Ω—Ç–æ —á–µ—Ä–µ–∑ MCP Server 2
        logger.info("Pipeline Step 3: Translating to Esperanto")
        translation_response = call_mcp_tool_sync_on_server(
            MCP_SERVER2_URL,
            "translate-to-esperanto",
            {"text": analysis}
        )

        if not translation_response:
            # –ü–µ—Ä–µ–≤–æ–¥ –æ–ø—Ü–∏–æ–Ω–∞–ª–µ–Ω - –Ω–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞
            logger.warning("Translation failed, using Russian version")
            result["translation"] = None
            result["error"] = "–ü–µ—Ä–µ–≤–æ–¥ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
        else:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –≤–µ—Ä–Ω—É–ª–∞—Å—å –ª–∏ –æ—à–∏–±–∫–∞ –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ
            try:
                error_check = json.loads(translation_response)
                if isinstance(error_check, dict) and "error" in error_check:
                    logger.warning(f"Translation error: {error_check['error']}")
                    result["translation"] = None
                    result["error"] = "–ü–µ—Ä–µ–≤–æ–¥ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
                else:
                    result["translation"] = translation_response
                    logger.info(f"Step 3 complete: Translation {len(translation_response)} chars")
            except (json.JSONDecodeError, ValueError):
                # –ù–µ JSON - –∑–Ω–∞—á–∏—Ç —ç—Ç–æ –æ–±—ã—á–Ω—ã–π –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
                result["translation"] = translation_response
                logger.info(f"Step 3 complete: Translation {len(translation_response)} chars")

        result["success"] = True
        result["step"] = "complete"
        return result

    except Exception as e:
        logger.error(f"Pipeline error at step {result['step']}: {e}", exc_info=True)
        result["error"] = str(e)
        return result


def handle_rag_query(question: str) -> dict:
    """
    –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∑–∞–ø—Ä–æ—Å —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º RAG –∏ —Å—Ä–∞–≤–Ω–∏—Ç—å —Ç—Ä–∏ –≤–∞—Ä–∏–∞–Ω—Ç–∞ –æ—Ç–≤–µ—Ç–∞.

    Args:
        question: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

    Returns:
        dict —Å –æ—Ç–≤–µ—Ç–∞–º–∏ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏:
        {
            "success": bool,
            "question": str,
            "answer_without_rag": str,
            "answer_with_rag_unfiltered": str,
            "answer_with_rag_filtered": str,
            "relevant_chunks_unfiltered": list,
            "relevant_chunks_filtered": list,
            "context_unfiltered": str,
            "context_filtered": str,
            "filter_stats": dict,
            "tokens_without_rag": dict,
            "tokens_with_rag_unfiltered": dict,
            "tokens_with_rag_filtered": dict,
            "error": str
        }
    """
    result = {
        "success": False,
        "question": question,
        "answer_without_rag": None,
        "answer_with_rag_unfiltered": None,
        "answer_with_rag_filtered": None,
        "relevant_chunks_unfiltered": [],
        "relevant_chunks_filtered": [],
        "context_unfiltered": "",
        "context_filtered": "",
        "filter_stats": {},
        "tokens_without_rag": {},
        "tokens_with_rag_unfiltered": {},
        "tokens_with_rag_filtered": {},
        "error": None
    }

    try:
        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å RAG
        if not RAG_AVAILABLE:
            result["error"] = "RAG module not available"
            return result

        logger.info(f"Processing RAG query: '{question}'")

        # –®–∞–≥ 1: –ü–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –ë–ï–ó RAG (baseline)
        logger.info("Step 1: Getting answer WITHOUT RAG")
        messages_without_rag = [
            {
                "role": "system",
                "content": "–¢—ã - –ø–æ–ª–µ–∑–Ω—ã–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç–æ—á–Ω–æ."
            },
            {
                "role": "user",
                "content": question
            }
        ]

        answer_without_rag, tokens_without_rag = call_deepseek_api(messages_without_rag)
        result["answer_without_rag"] = answer_without_rag
        result["tokens_without_rag"] = tokens_without_rag
        logger.info(f"Answer without RAG: {len(answer_without_rag)} chars, {tokens_without_rag['total_tokens']} tokens")

        # –®–∞–≥ 2a: –ù–∞–π—Ç–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫–∏ –ë–ï–ó —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        logger.info("Step 2a: Searching WITHOUT filtering")
        context_unfiltered, chunks_unfiltered, _ = rag_query(question, top_k=3, enable_filtering=False)

        if not chunks_unfiltered:
            logger.warning("No relevant chunks found")
            result["error"] = "No relevant documentation found"
            result["success"] = True  # Partial success - got answer without RAG
            return result

        result["relevant_chunks_unfiltered"] = chunks_unfiltered
        result["context_unfiltered"] = context_unfiltered
        logger.info(f"Found {len(chunks_unfiltered)} unfiltered chunks")

        # –®–∞–≥ 2b: –ü–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –° RAG (–±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏)
        logger.info("Step 2b: Getting answer WITH RAG (unfiltered)")
        messages_unfiltered = [
            {
                "role": "system",
                "content": (
                    "–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ Pond Mobile API. "
                    "–ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. "
                    "–ï—Å–ª–∏ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞, —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º. "
                    "–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, —á—ë—Ç–∫–æ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ."
                )
            },
            {
                "role": "user",
                "content": f"{context_unfiltered}\n\n---\n\n–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {question}"
            }
        ]

        answer_unfiltered, tokens_unfiltered = call_deepseek_api(messages_unfiltered)
        result["answer_with_rag_unfiltered"] = answer_unfiltered
        result["tokens_with_rag_unfiltered"] = tokens_unfiltered
        logger.info(f"Answer with RAG (unfiltered): {len(answer_unfiltered)} chars, {tokens_unfiltered['total_tokens']} tokens")

        # –®–∞–≥ 3a: –ù–∞–π—Ç–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫–∏ –° —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π (hybrid mode)
        logger.info("Step 3a: Searching WITH filtering (hybrid)")
        context_filtered, chunks_filtered, filter_stats = rag_query(
            question,
            top_k=3,
            enable_filtering=True,
            filtering_mode="hybrid"
        )

        result["filter_stats"] = filter_stats

        if not chunks_filtered:
            logger.warning("All chunks filtered out - using unfiltered results")
            # –û—Ç–∫–∞—Ç –∫ –Ω–µ—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º
            result["relevant_chunks_filtered"] = chunks_unfiltered
            result["context_filtered"] = context_unfiltered
            result["answer_with_rag_filtered"] = answer_unfiltered
            result["tokens_with_rag_filtered"] = tokens_unfiltered
            result["success"] = True
            return result

        result["relevant_chunks_filtered"] = chunks_filtered
        result["context_filtered"] = context_filtered
        logger.info(f"Found {len(chunks_filtered)} filtered chunks")

        # –®–∞–≥ 3b: –ü–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –° RAG (—Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π)
        logger.info("Step 3b: Getting answer WITH RAG (filtered)")
        messages_filtered = [
            {
                "role": "system",
                "content": (
                    "–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ Pond Mobile API. "
                    "–ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. "
                    "–ï—Å–ª–∏ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞, —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º. "
                    "–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, —á—ë—Ç–∫–æ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ."
                )
            },
            {
                "role": "user",
                "content": f"{context_filtered}\n\n---\n\n–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {question}"
            }
        ]

        answer_filtered, tokens_filtered = call_deepseek_api(messages_filtered)
        result["answer_with_rag_filtered"] = answer_filtered
        result["tokens_with_rag_filtered"] = tokens_filtered
        logger.info(f"Answer with RAG (filtered): {len(answer_filtered)} chars, {tokens_filtered['total_tokens']} tokens")

        result["success"] = True
        return result

    except Exception as e:
        logger.error(f"Error in RAG query: {e}", exc_info=True)
        result["error"] = str(e)
        return result


def send_tasks_summary(context: CallbackContext):
    """–û—Ç–ø—Ä–∞–≤–∫–∞ —Å–≤–æ–¥–∫–∏ –∑–∞–¥–∞—á –∫–∞–∂–¥—ã–µ N –º–∏–Ω—É—Ç."""
    if 'admin_chat_id' not in context.bot_data:
        logger.warning("admin_chat_id not set, skipping summary")
        return

    try:
        # –ü–æ–ª—É—á–∞–µ–º –∑–∞–¥–∞—á–∏ —á–µ—Ä–µ–∑ MCP
        tasks_json = call_mcp_tool_sync("get-tracker-tasks")

        if not tasks_json:
            logger.error("Failed to get tasks from MCP")
            return

        # –ü–∞—Ä—Å–∏–º JSON
        tasks = json.loads(tasks_json)

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å–≤–æ–¥–∫—É
        if isinstance(tasks, dict) and 'error' in tasks:
            summary = f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∑–∞–¥–∞—á:\n{tasks['error']}"
        elif isinstance(tasks, list):
            if len(tasks) == 0:
                summary = "üìã –ó–∞–¥–∞—á –≤ Yandex Tracker –Ω–µ—Ç"
            else:
                summary = f"üìã –°–≤–æ–¥–∫–∞ –∑–∞–¥–∞—á –∏–∑ Yandex Tracker ({len(tasks)} —à—Ç.):\n\n"
                for task in tasks[:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –º–∞–∫—Å–∏–º—É–º 10 –∑–∞–¥–∞—á
                    summary += f"üîπ {task.get('key')}: {task.get('summary')}\n"
                    summary += f"   –°—Ç–∞—Ç—É—Å: {task.get('status')}\n"
                    summary += f"   –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å: {task.get('assignee')}\n\n"

                if len(tasks) > 10:
                    summary += f"\n... –∏ –µ—â—ë {len(tasks) - 10} –∑–∞–¥–∞—á(–∏)"
        else:
            summary = f"üìã –ü–æ–ª—É—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ:\n{tasks_json[:500]}"

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º
        context.bot.send_message(
            chat_id=context.bot_data['admin_chat_id'],
            text=summary
        )
        logger.info(f"Sent tasks summary to {context.bot_data['admin_chat_id']}")

    except Exception as e:
        logger.error(f"Error in send_tasks_summary: {e}", exc_info=True)


def error_handler(update: Update, context: CallbackContext) -> None:
    """Log errors caused by updates."""
    logger.error(f"Update {update} caused error {context.error}")

def main() -> None:
    """Start the bot."""
    if not TOKEN:
        logger.error("TELEGRAM_BOT_TOKEN not found in environment variables")
        return

    # Create the Updater and pass it your bot's token.
    updater = Updater(TOKEN)

    # Get the dispatcher to register handlers
    dispatcher = updater.dispatcher

    # Register handlers
    dispatcher.add_handler(CommandHandler("start", start))
    dispatcher.add_handler(CommandHandler("help", help_command))
    dispatcher.add_handler(CommandHandler("stats", stats_command))
    dispatcher.add_handler(CommandHandler("compress", compress_command))
    dispatcher.add_handler(CommandHandler("clear", clear_command))
    dispatcher.add_handler(MessageHandler(Filters.text & ~Filters.command, ask_question))

    # Add error handler
    dispatcher.add_error_handler(error_handler)

    # Add periodic job for tasks summary (every 2 minutes = 120 seconds)
    # DISABLED: Regular task updates are disabled
    # job_queue = updater.job_queue
    # job_queue.run_repeating(send_tasks_summary, interval=120, first=120)
    # logger.info("Scheduled tasks summary job (every 2 minutes)")

    # Start the Bot
    updater.start_polling()

    # Run the bot until you press Ctrl-C or the process receives SIGINT,
    # SIGTERM or SIGABRT. This should be used most of the time, since
    # start_polling() is non-blocking and will stop the bot gracefully.
    updater.idle()

if __name__ == '__main__':
    main()
