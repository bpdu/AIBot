import logging
import requests
import json
import asyncio
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import Updater, CommandHandler, MessageHandler, Filters, CallbackContext, CallbackQueryHandler
from dotenv import load_dotenv
import os

# MCP imports
from mcp import ClientSession
from mcp.client.websocket import websocket_client

# RAG imports
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent / 'rag'))
try:
    from retrieval import rag_query
    from project_docs_retrieval import query_project_docs
    RAG_AVAILABLE = True
    PROJECT_DOCS_RAG_AVAILABLE = True
except ImportError as e:
    logger.warning(f"RAG module not available: {e}")
    RAG_AVAILABLE = False
    PROJECT_DOCS_RAG_AVAILABLE = False

# Load environment variables from the secret files
load_dotenv(dotenv_path='.secrets/bot-token.env')
load_dotenv(dotenv_path='.secrets/deepseek-api-key.env')

# Enable logging
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)

logger = logging.getLogger(__name__)

# Get the bot token from environment variables
TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')

# DeepSeek API configuration (using your paid account)
DEEPSEEK_API_KEY = os.getenv('DEEPSEEK_API_KEY')
DEEPSEEK_API_URL = 'https://api.deepseek.com/v1/chat/completions'
# Using DeepSeek Chat - your paid model
MODEL_NAME = 'deepseek-chat'  # Main DeepSeek model

# MCP configuration
MCP_SERVER_URL = "ws://localhost:8080/mcp"  # Yandex Tracker
MCP_SERVER2_URL = "ws://localhost:8081/mcp"  # Translation
MCP_GIT_SERVER_URL = "ws://localhost:8082/mcp"  # Git Integration

def start(update: Update, context: CallbackContext) -> None:
    """Send a message when the command /start is issued."""
    user = update.effective_user
    update.message.reply_text('–ü—Ä–∏–≤–µ—Ç! –≠—Ç–æ –±–æ—Ç —Å –º–æ–¥–µ–ª—å—é DeepSeek Chat —á–µ—Ä–µ–∑ DeepSeek API. –ó–∞–¥–∞–≤–∞–π –ª—é–±—ã–µ –≤–æ–ø—Ä–æ—Å—ã!')

def help_command(update: Update, context: CallbackContext) -> None:
    """
    Send a message when the command /help is issued.

    Supports two modes:
    1. /help - Shows basic help message
    2. /help <question> - Searches project documentation using RAG and Git MCP
    """
    # –ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ /help
    message_text = update.message.text
    question = message_text.replace('/help', '').strip()

    # –†–µ–∂–∏–º 1: –ë–∞–∑–æ–≤–∞—è —Å–ø—Ä–∞–≤–∫–∞
    if not question:
        help_text = (
            'ü§ñ AIBot - –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞\n\n'
            '–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:\n'
            '/start - –ù–∞—á–∞—Ç—å —Ä–∞–±–æ—Ç—É —Å –±–æ—Ç–æ–º\n'
            '/help - –ü–æ–∫–∞–∑–∞—Ç—å —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ\n'
            '/help <–≤–æ–ø—Ä–æ—Å> - –ü–æ–∏—Å–∫ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞\n'
            '/stats - –ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤ –∏ —Å–∂–∞—Ç–∏—è\n'
            '/compress - –°–∂–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –≤—Ä—É—á–Ω—É—é\n'
            '/clear - –û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞\n\n'
            'üìã Yandex Tracker –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è:\n'
            '–°–ø—Ä–æ—Å–∏—Ç–µ –ø—Ä–æ "–∑–∞–¥–∞—á–∏" –∏–ª–∏ "tracker" - –±–æ—Ç –ø–æ–ª—É—á–∏—Ç –∞–∫—Ç—É–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á —á–µ—Ä–µ–∑ MCP!\n\n'
            'üí° –ê–≤—Ç–æ—Å–∂–∞—Ç–∏–µ: –ö–∞–∂–¥—ã–µ 10 —Å–æ–æ–±—â–µ–Ω–∏–π –∏—Å—Ç–æ—Ä–∏—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–∂–∏–º–∞–µ—Ç—Å—è –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤!\n\n'
            'üîç –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è /help:\n'
            '/help –∫–∞–∫ –¥–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π MCP —Å–µ—Ä–≤–µ—Ä\n'
            '/help –ø—Ä–∞–≤–∏–ª–∞ —Å—Ç–∏–ª—è –∫–æ–¥–∞\n'
            '/help –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ RAG —Å–∏—Å—Ç–µ–º—ã\n\n'
            '–ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ –≤–æ–ø—Ä–æ—Å, –∏ —è –æ—Ç–≤–µ—á—É —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏ DeepSeek Chat!'
        )
        update.message.reply_text(help_text)
        return

    # –†–µ–∂–∏–º 2: –ü–æ–∏—Å–∫ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞
    if not PROJECT_DOCS_RAG_AVAILABLE:
        update.message.reply_text(
            "‚ö†Ô∏è –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.\n"
            "–ó–∞–ø—É—Å—Ç–∏—Ç–µ: python rag/create-project-docs-embeddings.py"
        )
        return

    update.message.reply_text(
        f"üîç –ò—â—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞...\n"
        f"–í–æ–ø—Ä–æ—Å: {question}"
    )

    try:
        # –ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ Git —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏
        git_context = ""
        try:
            git_branch_result = call_mcp_tool_sync_on_server(
                MCP_GIT_SERVER_URL,
                "get-current-branch"
            )
            if git_branch_result:
                git_data = json.loads(git_branch_result)
                if git_data.get("success"):
                    git_context = f"\n\n–¢–µ–∫—É—â–∞—è –≤–µ—Ç–∫–∞: {git_data.get('branch', 'unknown')}"
        except Exception as e:
            logger.warning(f"Failed to get git context: {e}")

        # –ü–æ–∏—Å–∫ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞
        logger.info(f"Searching project docs for: '{question}'")
        docs_context, docs_chunks = query_project_docs(question, top_k=5)

        if not docs_chunks:
            update.message.reply_text(
                "‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞.\n"
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å."
            )
            return

        # –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –ø—Ä–æ–º–ø—Ç –¥–ª—è DeepSeek
        system_message = {
            "role": "system",
            "content": (
                "–¢—ã ‚Äî AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞ AIBot. "
                "–ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è –æ—Ç–≤–µ—Ç–∞. "
                "–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, —á—ë—Ç–∫–æ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ. "
                "–ï—Å–ª–∏ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –Ω–µ—Ç –Ω—É–∂–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º."
            )
        }

        user_message = {
            "role": "user",
            "content": (
                f"=== –î–û–ö–£–ú–ï–ù–¢–ê–¶–ò–Ø –ü–†–û–ï–ö–¢–ê ===\n{docs_context}\n\n"
                f"=== –ö–û–ù–¢–ï–ö–°–¢ –†–ï–ü–û–ó–ò–¢–û–†–ò–Ø ==={git_context}\n\n"
                f"=== –í–û–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø ===\n{question}"
            )
        }

        messages = [system_message, user_message]

        # –í—ã–∑–≤–∞—Ç—å DeepSeek API
        logger.info("Calling DeepSeek API with project docs context...")
        answer, tokens = call_deepseek_api(messages)

        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç
        response_parts = [answer]

        # –î–æ–±–∞–≤–∏—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏
        response_parts.append("\n" + "="*40)
        response_parts.append("üìö –ò–°–¢–û–ß–ù–ò–ö–ò")
        response_parts.append("="*40)

        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º
        docs_map = {}
        for chunk in docs_chunks:
            doc_name = chunk['doc_name']
            if doc_name not in docs_map:
                docs_map[doc_name] = []
            docs_map[doc_name].append(chunk['heading'])

        for doc_name, headings in docs_map.items():
            response_parts.append(f"\nüìÑ {doc_name}")
            for heading in headings:
                response_parts.append(f"  ‚Ä¢ {heading}")

        # –î–æ–±–∞–≤–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        response_parts.append(f"\n{'='*40}")
        response_parts.append("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
        response_parts.append("="*40)
        response_parts.append(f"‚Ä¢ –ù–∞–π–¥–µ–Ω–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {len(docs_chunks)}")
        response_parts.append(f"‚Ä¢ –¢–æ–∫–µ–Ω–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {tokens['total_tokens']}")

        full_response = "\n".join(response_parts)

        # –û—Ç–ø—Ä–∞–≤–∏—Ç—å –æ—Ç–≤–µ—Ç (—Å —Ä–∞–∑–±–∏–µ–Ω–∏–µ–º, –µ—Å–ª–∏ –¥–ª–∏–Ω–Ω—ã–π)
        send_long_message(update, full_response)

        logger.info("Project docs help query completed successfully")

    except Exception as e:
        logger.error(f"Error in project docs help: {e}", exc_info=True)
        update.message.reply_text(
            f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏: {str(e)}"
        )

def stats_command(update: Update, context: CallbackContext) -> None:
    """Show token usage statistics."""
    if 'token_stats' not in context.user_data or context.user_data['token_stats']['total_requests'] == 0:
        update.message.reply_text('üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—É—Å—Ç–∞. –û—Ç–ø—Ä–∞–≤—å—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –Ω–∞—á–∞–ª–∞.')
        return

    stats = context.user_data['token_stats']

    # Calculate averages
    avg_total = stats['total_tokens'] / stats['total_requests']
    avg_prompt = stats['total_prompt_tokens'] / stats['total_requests']
    avg_completion = stats['total_completion_tokens'] / stats['total_requests']

    stats_text = (
        f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤\n"
        f"{'=' * 35}\n\n"
        f"–í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {stats['total_requests']}\n\n"
        f"–û–±—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:\n"
        f"‚Ä¢ –í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤: {stats['total_tokens']}\n"
        f"‚Ä¢ –¢–æ–∫–µ–Ω–æ–≤ –≤ –∑–∞–ø—Ä–æ—Å–∞—Ö: {stats['total_prompt_tokens']}\n"
        f"‚Ä¢ –¢–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–∞—Ö: {stats['total_completion_tokens']}\n\n"
        f"–°—Ä–µ–¥–Ω–µ–µ –Ω–∞ –∑–∞–ø—Ä–æ—Å:\n"
        f"‚Ä¢ –í—Å–µ–≥–æ: {avg_total:.1f} —Ç–æ–∫–µ–Ω–æ–≤\n"
        f"‚Ä¢ –ó–∞–ø—Ä–æ—Å: {avg_prompt:.1f} —Ç–æ–∫–µ–Ω–æ–≤\n"
        f"‚Ä¢ –û—Ç–≤–µ—Ç: {avg_completion:.1f} —Ç–æ–∫–µ–Ω–æ–≤\n"
    )

    # Show compression statistics
    if 'compression_stats' in context.user_data and context.user_data['compression_stats']['total_compressions'] > 0:
        comp_stats = context.user_data['compression_stats']
        stats_text += f"\n{'=' * 35}\n"
        stats_text += "üóúÔ∏è –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∂–∞—Ç–∏—è:\n\n"
        stats_text += f"‚Ä¢ –í—Å–µ–≥–æ —Å–∂–∞—Ç–∏–π: {comp_stats['total_compressions']}\n"
        stats_text += f"‚Ä¢ –°–æ–æ–±—â–µ–Ω–∏–π —Å–∂–∞—Ç–æ: {comp_stats['messages_compressed']}\n"
        stats_text += f"‚Ä¢ –¢–æ–∫–µ–Ω–æ–≤ —Å—ç–∫–æ–Ω–æ–º–ª–µ–Ω–æ: ~{comp_stats['tokens_saved']}\n"

    # Show last 5 requests
    if stats['requests_history']:
        stats_text += f"\n{'=' * 35}\n"
        stats_text += f"–ü–æ—Å–ª–µ–¥–Ω–∏–µ {min(5, len(stats['requests_history']))} –∑–∞–ø—Ä–æ—Å–æ–≤:\n\n"

        for i, req in enumerate(stats['requests_history'][-5:], 1):
            stats_text += (
                f"{i}. {req['timestamp']}\n"
                f"   –î–ª–∏–Ω–∞ –≤–æ–ø—Ä–æ—Å–∞: {req['question_length']} —Å–∏–º–≤–æ–ª–æ–≤\n"
                f"   –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {req['response_length']} —Å–∏–º–≤–æ–ª–æ–≤\n"
                f"   –¢–æ–∫–µ–Ω—ã: {req['tokens']['total_tokens']} "
                f"({req['tokens']['prompt_tokens']}+{req['tokens']['completion_tokens']})\n\n"
            )

    update.message.reply_text(stats_text)

def clear_command(update: Update, context: CallbackContext) -> None:
    """Clear conversation history."""
    if 'conversation_history' in context.user_data:
        context.user_data['conversation_history'] = []
    update.message.reply_text('üóëÔ∏è –ò—Å—Ç–æ—Ä–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –æ—á–∏—â–µ–Ω–∞!')

def compress_command(update: Update, context: CallbackContext) -> None:
    """Manually compress conversation history."""
    if 'conversation_history' not in context.user_data:
        update.message.reply_text('‚ùå –ò—Å—Ç–æ—Ä–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –ø—É—Å—Ç–∞!')
        return

    history = context.user_data['conversation_history']
    non_system_messages = [msg for msg in history if msg.get('role') != 'system']

    if len(non_system_messages) < 2:
        update.message.reply_text('‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è —Å–∂–∞—Ç–∏—è (–º–∏–Ω–∏–º—É–º 2)')
        return

    update.message.reply_text('üóúÔ∏è –°–∂–∏–º–∞—é –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞...')

    compression_result = compress_conversation_history(context, force=True)

    if compression_result.get('compressed'):
        # Reset message counter after manual compression
        old_counter = context.user_data.get('message_counter', 0)
        context.user_data['message_counter'] = 0

        response = (
            f"‚úÖ –ò—Å—Ç–æ—Ä–∏—è —É—Å–ø–µ—à–Ω–æ —Å–∂–∞—Ç–∞!\n\n"
            f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∂–∞—Ç–∏—è:\n"
            f"‚Ä¢ –°–æ–æ–±—â–µ–Ω–∏–π –¥–æ: {compression_result['messages_before']}\n"
            f"‚Ä¢ –°–æ–æ–±—â–µ–Ω–∏–π –ø–æ—Å–ª–µ: {compression_result['messages_after']}\n"
            f"‚Ä¢ –¢–æ–∫–µ–Ω–æ–≤ –¥–æ: ~{compression_result['tokens_before']}\n"
            f"‚Ä¢ –¢–æ–∫–µ–Ω–æ–≤ –ø–æ—Å–ª–µ: ~{compression_result['tokens_after']}\n"
            f"‚Ä¢ –°—ç–∫–æ–Ω–æ–º–ª–µ–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: ~{compression_result['tokens_saved']}\n"
            f"‚Ä¢ –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∂–∞—Ç–∏—è: {compression_result['compression_ratio']}%\n"
            f"‚Ä¢ –≠–∫–æ–Ω–æ–º–∏—è: {100 - compression_result['compression_ratio']:.0f}%\n\n"
            f"üîÑ –°—á—ë—Ç—á–∏–∫ —Å–æ–æ–±—â–µ–Ω–∏–π —Å–±—Ä–æ—à–µ–Ω (–±—ã–ª–æ: #{old_counter})"
        )
        update.message.reply_text(response)
    else:
        update.message.reply_text(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∂–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é: {compression_result.get('reason', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")

def ask_question(update: Update, context: CallbackContext) -> None:
    """Send the user's question to DeepSeek API and return the response."""
    if update.message is None or update.message.text is None:
        update.message.reply_text("Sorry, I couldn't process that message.")
        return

    user_question = update.message.text

    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å chat_id –ø—Ä–∏ –ø–µ—Ä–≤–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏
    if 'admin_chat_id' not in context.bot_data:
        context.bot_data['admin_chat_id'] = update.message.chat_id
        logger.info(f"Saved admin_chat_id: {update.message.chat_id}")

    # Initialize conversation history and current date in context if it doesn't exist
    if 'conversation_history' not in context.user_data:
        context.user_data['conversation_history'] = []

    # Initialize token statistics
    if 'token_stats' not in context.user_data:
        context.user_data['token_stats'] = {
            'total_requests': 0,
            'total_tokens': 0,
            'total_prompt_tokens': 0,
            'total_completion_tokens': 0,
            'requests_history': []
        }

    # Initialize message counter
    if 'message_counter' not in context.user_data:
        context.user_data['message_counter'] = 0

    # Increment message counter
    context.user_data['message_counter'] += 1
    current_message_num = context.user_data['message_counter']

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –ø—Ä–æ –∑–∞–¥–∞—á–∏ –∏–∑ Tracker
    # –î–µ–Ω—å 22: –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ keywords –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
    keywords = [
        # Tracker/issue keywords
        "–∑–∞–¥–∞—á", "task", "tracker", "issue", "—Ç—Ä–µ–∫–µ—Ä", "ticket", "—Ç–∏–∫–µ—Ç",
        # Problem keywords
        "error", "problem", "not working", "fail", "bug", "–æ—à–∏–±–∫",
        # HTTP errors
        "401", "403", "404", "429", "500",
        # Support keywords
        "alert", "warning", "90%", "threshold", "custom", "support"
    ]
    message_lower = user_question.lower()

    logger.info(f"Checking message for tracker keywords: '{message_lower}'")
    keyword_found = any(keyword in message_lower for keyword in keywords)
    logger.info(f"Keyword found: {keyword_found}")

    # –î–µ–Ω—å 22: –ü–æ–ª—É—á–∏—Ç—å –∑–∞–¥–∞—á–∏ –∏–∑ Tracker (–µ—Å–ª–∏ –µ—Å—Ç—å keywords)
    tracker_info = None
    if keyword_found:
        logger.info("Detected tracker-related question, fetching tasks...")
        update.message.reply_text("üîÑ –ü—Ä–æ–≤–µ—Ä—è—é –æ—Ç–∫—Ä—ã—Ç—ã–µ –∑–∞–¥–∞—á–∏ –≤ Yandex Tracker...")

        try:
            # –ü—Ä–æ—Å—Ç–æ–π –≤—ã–∑–æ–≤ MCP –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∑–∞–¥–∞—á (–Ω–µ –ø–æ–ª–Ω—ã–π pipeline)
            tasks_json = call_mcp_tool_sync("get-tracker-tasks")

            if tasks_json:
                # –ü–∞—Ä—Å–∏–º –∑–∞–¥–∞—á–∏
                tasks_data = json.loads(tasks_json)

                # MCP –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ª–∏–±–æ –º–∞—Å—Å–∏–≤ –∑–∞–¥–∞—á, –ª–∏–±–æ –æ–±—ä–µ–∫—Ç —Å –æ—à–∏–±–∫–æ–π
                if isinstance(tasks_data, list):
                    # –£—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–∏–ª–∏ –º–∞—Å—Å–∏–≤ –∑–∞–¥–∞—á
                    tasks = tasks_data
                    logger.info(f"Retrieved {len(tasks)} tasks from Tracker")

                    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫—Ä–∞—Ç–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–¥–∞—á–∞—Ö –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                    tracker_info = "–û—Ç–∫—Ä—ã—Ç—ã–µ –∑–∞–¥–∞—á–∏ –∏–∑ Yandex Tracker:\n"
                    for task in tasks[:10]:  # –ú–∞–∫—Å–∏–º—É–º 10 –∑–∞–¥–∞—á
                        key = task.get("key", "N/A")
                        summary = task.get("summary", "")
                        status = task.get("status", "Unknown")  # status —É–∂–µ —Å—Ç—Ä–æ–∫–∞ –≤ formatted_task
                        tracker_info += f"‚Ä¢ {key}: {summary}\n  –°—Ç–∞—Ç—É—Å: {status}\n"
                elif isinstance(tasks_data, dict) and "error" in tasks_data:
                    # –ü–æ–ª—É—á–∏–ª–∏ –æ—à–∏–±–∫—É
                    logger.warning(f"Tracker returned error: {tasks_data['error']}")
                    tracker_info = f"–û—à–∏–±–∫–∞ Tracker: {tasks_data['error']}"
                else:
                    logger.warning("Unexpected response format from Tracker")
                    tracker_info = "–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç Tracker."
            else:
                logger.warning("MCP call returned empty result")
                tracker_info = "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∑–∞–¥–∞—á–∏ –∏–∑ Tracker."

        except Exception as e:
            logger.error(f"Error fetching tracker tasks: {e}", exc_info=True)
            tracker_info = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∑–∞–¥–∞—á –∏–∑ Tracker: {str(e)}"

        # –ù–ï –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è! –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–ª—è –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –ø—Ä–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
    monitoring_keywords = ["–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥", "health", "—Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–µ—Ä–≤–µ—Ä–∞", "–º–µ—Ç—Ä–∏–∫–∏", "monitoring", "—Å—Ç–∞—Ç—É—Å —Å–µ—Ä–≤–µ—Ä–∞"]
    monitoring_keyword_found = any(keyword in message_lower for keyword in monitoring_keywords)

    if monitoring_keyword_found:
        logger.info("Detected monitoring-related question, collecting host metrics...")
        update.message.reply_text("üîÑ –°–æ–±–∏—Ä–∞—é –º–µ—Ç—Ä–∏–∫–∏ —Ö–æ—Å—Ç–∞...")

        try:
            # –í—ã–∑–≤–∞—Ç—å MCP tool –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫
            monitoring_result_json = call_mcp_tool_sync_on_server(
                MCP_SERVER_URL,
                "get-host-metrics"
            )

            if not monitoring_result_json:
                update.message.reply_text("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏. MCP —Å–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.")
                return

            # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            try:
                metrics = json.loads(monitoring_result_json)

                if metrics.get("success"):
                    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫—Ä–∞—Å–∏–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
                    cpu = metrics.get("cpu", {})
                    memory = metrics.get("memory", {})
                    disk = metrics.get("disk", {})
                    uptime = metrics.get("uptime", {})
                    system = metrics.get("system", {})
                    timestamp = metrics.get("timestamp", "")

                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —ç–º–æ–¥–∑–∏ –¥–ª—è —É—Ä–æ–≤–Ω—è –∑–∞–≥—Ä—É–∑–∫–∏
                    cpu_emoji = "üü¢" if cpu.get("percent", 0) < 50 else "üü°" if cpu.get("percent", 0) < 80 else "üî¥"
                    mem_emoji = "üü¢" if memory.get("percent", 0) < 50 else "üü°" if memory.get("percent", 0) < 80 else "üî¥"
                    disk_emoji = "üü¢" if disk.get("percent", 0) < 50 else "üü°" if disk.get("percent", 0) < 80 else "üî¥"

                    metrics_msg = (
                        f"üìä –ú–µ—Ç—Ä–∏–∫–∏ —Ö–æ—Å—Ç–∞\n"
                        f"{'=' * 30}\n"
                        f"üïê {timestamp}\n\n"
                        f"{cpu_emoji} CPU:\n"
                        f"  ‚Ä¢ –ó–∞–≥—Ä—É–∑–∫–∞: {cpu.get('percent', 0):.1f}%\n"
                        f"  ‚Ä¢ –Ø–¥—Ä–∞: {cpu.get('cores', 'N/A')}\n"
                        f"  ‚Ä¢ –ß–∞—Å—Ç–æ—Ç–∞: {cpu.get('frequency_mhz', 0)} MHz\n\n"
                        f"{mem_emoji} –ü–∞–º—è—Ç—å:\n"
                        f"  ‚Ä¢ –ó–∞–≥—Ä—É–∑–∫–∞: {memory.get('percent', 0):.1f}%\n"
                        f"  ‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {memory.get('used_gb', 0):.2f} GB\n"
                        f"  ‚Ä¢ –í—Å–µ–≥–æ: {memory.get('total_gb', 0):.2f} GB\n\n"
                        f"{disk_emoji} –î–∏—Å–∫:\n"
                        f"  ‚Ä¢ –ó–∞–≥—Ä—É–∑–∫–∞: {disk.get('percent', 0):.1f}%\n"
                        f"  ‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {disk.get('used_gb', 0):.2f} GB\n"
                        f"  ‚Ä¢ –í—Å–µ–≥–æ: {disk.get('total_gb', 0):.2f} GB\n\n"
                        f"‚è±Ô∏è Uptime: {uptime.get('formatted', 'N/A')}\n"
                        f"üîÑ –ó–∞–ø—É—Å–∫: {uptime.get('boot_time', 'N/A')}\n\n"
                        f"üíª –°–∏—Å—Ç–µ–º–∞:\n"
                        f"  ‚Ä¢ –•–æ—Å—Ç: {system.get('hostname', 'N/A')}\n"
                        f"  ‚Ä¢ –û–°: {system.get('platform', 'N/A')}\n"
                        f"  ‚Ä¢ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {system.get('architecture', 'N/A')}\n"
                        f"  ‚Ä¢ IP: {system.get('ip_address', 'N/A')}\n"
                        f"  ‚Ä¢ –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {system.get('temperature', 'N/A')}"
                    )
                    update.message.reply_text(metrics_msg)
                else:
                    # –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –º–µ—Ç—Ä–∏–∫
                    error = metrics.get("error", "Unknown error")
                    update.message.reply_text(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –º–µ—Ç—Ä–∏–∫: {error}")

            except json.JSONDecodeError:
                # –ù–µ JSON –æ—Ç–≤–µ—Ç
                update.message.reply_text(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {monitoring_result_json[:500]}")

            logger.info("Monitoring request completed")
            return

        except Exception as e:
            logger.error(f"Error getting metrics: {e}", exc_info=True)
            update.message.reply_text(
                f"‚ö†Ô∏è –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –º–µ—Ç—Ä–∏–∫: {str(e)}"
            )
            return

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø—Ä–æ API (–î–µ–Ω—å 17: RAG, –î–µ–Ω—å 22: –∫–æ–º–±–∏–Ω–∞—Ü–∏—è —Å Tracker)
    api_keywords = ["api", "endpoint", "sim", "esim", "inventory", "pond mobile", "msisdn",
                    "transfer", "webhook", "country", "countries", "group", "whitelist"]
    api_keyword_found = any(keyword in message_lower for keyword in api_keywords)

    if api_keyword_found and RAG_AVAILABLE:
        logger.info("Detected API-related question, using RAG with conversation history...")
        update.message.reply_text("üîç –ò—â—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ Pond Mobile API...")

        try:
            # –í—ã–ø–æ–ª–Ω–∏—Ç—å RAG-–∑–∞–ø—Ä–æ—Å —Å –ø–µ—Ä–µ–¥–∞—á–µ–π –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞ –∏ tracker info
            rag_result = handle_rag_query(
                question=user_question,
                conversation_history=context.user_data.get('conversation_history', []),
                tracker_info=tracker_info  # –î–µ–Ω—å 22: –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ Tracker
            )

            if not rag_result["success"]:
                error_msg = f"‚ö†Ô∏è –û—à–∏–±–∫–∞ RAG: {rag_result.get('error', 'Unknown error')}"
                update.message.reply_text(error_msg)
                # –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Å –æ–±—ã—á–Ω—ã–º –æ—Ç–≤–µ—Ç–æ–º (fallback)
            else:
                # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å –∏ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –µ–¥–∏–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                response_message = format_rag_response_for_telegram(rag_result)
                send_long_message(update, response_message)

                # –í–ê–ñ–ù–û: –î–æ–±–∞–≤–∏—Ç—å –æ—Ç–≤–µ—Ç –≤ –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞
                context.user_data['conversation_history'].append({
                    "role": "assistant",
                    "content": rag_result['answer']  # –¢–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞
                })

                logger.info("RAG query completed successfully with tracker context")
                return

        except Exception as e:
            logger.error(f"Error in RAG processing: {e}", exc_info=True)
            update.message.reply_text(
                f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ RAG-–∑–∞–ø—Ä–æ—Å–∞: {str(e)}\n"
                "–ü—Ä–æ–¥–æ–ª–∂–∞—é —Å –æ–±—ã—á–Ω—ã–º –æ—Ç–≤–µ—Ç–æ–º..."
            )

    # –î–µ–Ω—å 22: –ï—Å–ª–∏ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ tracker_info (–±–µ–∑ API keywords), –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –≤ –æ–±—ã—á–Ω–æ–º DeepSeek –∑–∞–ø—Ä–æ—Å–µ
    if tracker_info and not api_keyword_found:
        logger.info("Adding tracker context to conversation for non-API question")
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ Tracker –∫–∞–∫ system message –≤ –Ω–∞—á–∞–ª–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        tracker_system_msg = {
            "role": "system",
            "content": f"=== –ò–ù–§–û–†–ú–ê–¶–ò–Ø –ò–ó YANDEX TRACKER ===\n{tracker_info}"
        }
        context.user_data['conversation_history'].insert(0, tracker_system_msg)

    # Add user message to conversation history
    context.user_data['conversation_history'].append({
        "role": "user",
        "content": user_question
    })

    # Auto-compress every 10 messages (excluding system messages)
    non_system_messages = [msg for msg in context.user_data['conversation_history'] if msg.get('role') != 'system']
    if len(non_system_messages) >= 10:
        compression_result = compress_conversation_history(context)
        if compression_result.get('compressed'):
            # Reset message counter after compression
            context.user_data['message_counter'] = 0
            update.message.reply_text(
                f"üóúÔ∏è –ê–≤—Ç–æ—Å–∂–∞—Ç–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ (–ø–æ—Å–ª–µ —Å–æ–æ–±—â–µ–Ω–∏—è #{current_message_num}):\n"
                f"‚Ä¢ –°–∂–∞—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {compression_result['messages_before']}\n"
                f"‚Ä¢ –¢–æ–∫–µ–Ω–æ–≤ –±—ã–ª–æ: ~{compression_result['tokens_before']}\n"
                f"‚Ä¢ –¢–æ–∫–µ–Ω–æ–≤ —Å—Ç–∞–ª–æ: ~{compression_result['tokens_after']}\n"
                f"‚Ä¢ –≠–∫–æ–Ω–æ–º–∏—è: ~{compression_result['tokens_saved']} —Ç–æ–∫–µ–Ω–æ–≤ ({100 - compression_result['compression_ratio']:.0f}%)\n"
                f"‚Ä¢ –°—á—ë—Ç—á–∏–∫ —Å–æ–æ–±—â–µ–Ω–∏–π —Å–±—Ä–æ—à–µ–Ω!"
            )

    # Estimate input length for warning
    estimated_input_chars = sum(len(msg['content']) for msg in context.user_data['conversation_history'])
    estimated_input_tokens = estimated_input_chars // 4  # Rough estimate: 1 token ‚âà 4 chars

    # Warn if input is very long
    if estimated_input_tokens > 7000:
        update.message.reply_text(
            "‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: –û—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å!\n"
            f"–ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ {estimated_input_tokens} —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∏—Å—Ç–æ—Ä–∏–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞.\n"
            "–ú–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤–µ—Å—å –∫–æ–Ω—Ç–µ–∫—Å—Ç."
        )

    # Call DeepSeek API with conversation history
    gpt_response, token_usage = call_deepseek_api(context.user_data['conversation_history'])

    # Add assistant response to conversation history
    context.user_data['conversation_history'].append({
        "role": "assistant",
        "content": gpt_response
    })

    # Update token statistics
    context.user_data['token_stats']['total_requests'] += 1
    context.user_data['token_stats']['total_tokens'] += token_usage['total_tokens']
    context.user_data['token_stats']['total_prompt_tokens'] += token_usage['prompt_tokens']
    context.user_data['token_stats']['total_completion_tokens'] += token_usage['completion_tokens']

    # Add to request history (keep last 20 requests)
    from datetime import datetime
    context.user_data['token_stats']['requests_history'].append({
        'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        'question_length': len(user_question),
        'response_length': len(gpt_response),
        'tokens': token_usage
    })
    if len(context.user_data['token_stats']['requests_history']) > 20:
        context.user_data['token_stats']['requests_history'].pop(0)

    # Format response with token information
    token_info = (
        f"\n\nüìä –°–æ–æ–±—â–µ–Ω–∏–µ #{current_message_num} | –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤:\n"
        f"‚Ä¢ –ó–∞–ø—Ä–æ—Å: {token_usage['prompt_tokens']}\n"
        f"‚Ä¢ –û—Ç–≤–µ—Ç: {token_usage['completion_tokens']}\n"
        f"‚Ä¢ –í—Å–µ–≥–æ: {token_usage['total_tokens']}"
    )

    # Send the response directly to the user with token info
    full_response = gpt_response + token_info
    update.message.reply_text(full_response)

def create_conversation_summary(messages) -> str:
    """Create a summary of conversation history using DeepSeek API.

    Args:
        messages: List of conversation messages

    Returns:
        str: Summary of the conversation
    """
    if not messages:
        return ""

    # Prepare prompt for summarization
    conversation_text = "\n".join([
        f"{msg['role'].upper()}: {msg['content']}"
        for msg in messages
    ])

    summary_prompt = f"""–°–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞.
–°–æ—Ö—Ä–∞–Ω–∏ –í–°–Æ –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, —Ñ–∞–∫—Ç—ã, –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –≤—ã–≤–æ–¥—ã.
–†–µ–∑—é–º–µ –¥–æ–ª–∂–Ω–æ –ø–æ–∑–≤–æ–ª–∏—Ç—å –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.

–î–∏–∞–ª–æ–≥:
{conversation_text}

–ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ (–Ω–∞ —Ä—É—Å—Å–∫–æ–º):"""

    summary_messages = [
        {"role": "system", "content": "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–∑–¥–∞—ë—Ç –∫—Ä–∞—Ç–∫–∏–µ —Ä–µ–∑—é–º–µ –¥–∏–∞–ª–æ–≥–æ–≤, —Å–æ—Ö—Ä–∞–Ω—è—è –≤—Å—é –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é."},
        {"role": "user", "content": summary_prompt}
    ]

    try:
        response_text, _ = call_deepseek_api(summary_messages)
        return response_text
    except Exception as e:
        logger.error(f"Error creating summary: {e}")
        # Fallback: create simple summary
        return f"–û–±—Å—É–∂–¥–∞–ª–æ—Å—å {len(messages)} —Å–æ–æ–±—â–µ–Ω–∏–π. –¢–µ–º—ã: {', '.join(set([msg['content'][:30] + '...' for msg in messages[:3]]))}"

def compress_conversation_history(context: CallbackContext, force: bool = False) -> dict:
    """Compress conversation history by creating a summary.

    Args:
        context: Telegram context with user_data
        force: Force compression even if threshold not reached

    Returns:
        dict: Compression statistics
    """
    if 'conversation_history' not in context.user_data:
        return {'compressed': False, 'reason': 'No history'}

    history = context.user_data['conversation_history']

    # Skip if history is too short (unless forced)
    if len(history) < 10 and not force:
        return {'compressed': False, 'reason': 'History too short', 'messages': len(history)}

    # Calculate tokens before compression
    chars_before = sum(len(msg['content']) for msg in history)
    tokens_before = chars_before // 4

    # Create summary of all messages except system messages
    messages_to_summarize = [msg for msg in history if msg.get('role') != 'system']

    if not messages_to_summarize:
        return {'compressed': False, 'reason': 'No messages to compress'}

    logger.info(f"Compressing {len(messages_to_summarize)} messages...")
    summary = create_conversation_summary(messages_to_summarize)

    # Replace history with summary
    context.user_data['conversation_history'] = [
        {
            "role": "system",
            "content": f"–ü—Ä–µ–¥—ã–¥—É—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ (—Ä–µ–∑—é–º–µ {len(messages_to_summarize)} —Å–æ–æ–±—â–µ–Ω–∏–π):\n{summary}"
        }
    ]

    # Calculate tokens after compression
    chars_after = len(summary)
    tokens_after = chars_after // 4

    # Update compression statistics
    if 'compression_stats' not in context.user_data:
        context.user_data['compression_stats'] = {
            'total_compressions': 0,
            'tokens_saved': 0,
            'messages_compressed': 0
        }

    context.user_data['compression_stats']['total_compressions'] += 1
    context.user_data['compression_stats']['tokens_saved'] += (tokens_before - tokens_after)
    context.user_data['compression_stats']['messages_compressed'] += len(messages_to_summarize)

    return {
        'compressed': True,
        'messages_before': len(messages_to_summarize),
        'messages_after': 1,
        'tokens_before': tokens_before,
        'tokens_after': tokens_after,
        'tokens_saved': tokens_before - tokens_after,
        'compression_ratio': round(tokens_after / tokens_before * 100, 1) if tokens_before > 0 else 0
    }

def call_deepseek_api(messages) -> tuple:
    """Call DeepSeek API and return the response with token usage.

    Returns:
        tuple: (response_text, token_usage_dict) where token_usage_dict contains:
            - total_tokens: total tokens used
            - prompt_tokens: tokens in the prompt
            - completion_tokens: tokens in the completion
    """
    if not DEEPSEEK_API_KEY:
        return ("DeepSeek API key not configured. Please check your environment variables.",
                {"total_tokens": 0, "prompt_tokens": 0, "completion_tokens": 0})

    headers = {
        'Authorization': f'Bearer {DEEPSEEK_API_KEY}',
        'Content-Type': 'application/json'
    }

    # Add system message if not present
    formatted_messages = []
    if not any(msg.get('role') == 'system' for msg in messages):
        formatted_messages.append({
            "role": "system",
            "content": "–¢—ã ‚Äî –ø–æ–ª–µ–∑–Ω—ã–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç–æ—á–Ω–æ –∏ –ø–æ–ª–µ–∑–Ω–æ."
        })

    # Add conversation history
    formatted_messages.extend(messages)

    payload = {
        "model": MODEL_NAME,
        "messages": formatted_messages,
        "temperature": 0.7,
        "max_tokens": 2000
    }

    try:
        response = requests.post(DEEPSEEK_API_URL, headers=headers, data=json.dumps(payload))
        response.raise_for_status()
        result = response.json()

        # Extract response text
        response_text = result['choices'][0]['message']['content']

        # Extract token usage from response
        usage = result.get('usage', {})

        # Get token counts
        prompt_tokens = usage.get('prompt_tokens', 0)
        completion_tokens = usage.get('completion_tokens', 0)
        total_tokens = usage.get('total_tokens', 0)

        token_usage = {
            'total_tokens': total_tokens,
            'prompt_tokens': prompt_tokens,
            'completion_tokens': completion_tokens
        }

        logger.info(f"Token usage: Total={total_tokens}, Prompt={prompt_tokens}, Completion={completion_tokens}")

        return (response_text, token_usage)
    except Exception as e:
        logger.error(f"Error calling DeepSeek API: {e}")
        if hasattr(e, 'response') and e.response is not None:
            logger.error(f"Response status: {e.response.status_code}")
            logger.error(f"Response body: {e.response.text}")
        error_msg = f"Sorry, I encountered an error while processing your request: {str(e)}"
        return (error_msg, {"total_tokens": 0, "prompt_tokens": 0, "completion_tokens": 0})


def analyze_tasks_order(tasks_json: str) -> str:
    """
    –ê–Ω–∞–ª–∏–∑ –∑–∞–¥–∞—á –∏ —Å–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —á–µ—Ä–µ–∑ DeepSeek.

    Args:
        tasks_json: JSON —Å—Ç—Ä–æ–∫–∞ —Å –∑–∞–¥–∞—á–∞–º–∏ –∏–∑ Yandex Tracker

    Returns:
        –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç—á—ë—Ç —Å –∞–Ω–∞–ª–∏–∑–æ–º –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–º –ø–æ—Ä—è–¥–∫–æ–º –∑–∞–¥–∞—á
    """
    analysis_prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π —Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á –∏–∑ Yandex Tracker.

–ó–∞–¥–∞—á–∏:
{tasks_json}

–¢–≤–æ—è –∑–∞–¥–∞—á–∞:
1. –û–ø—Ä–µ–¥–µ–ª–∏ –ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø–æ—Ä—è–¥–æ–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á
2. –ù–∞–π–¥–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–£—Ç–æ—á–Ω–∏—Ç—å –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å" –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø–µ—Ä–µ–¥ "–ó–∞–∫–∞–∑–∞—Ç—å")
3. –£—á—Ç–∏ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –∏ —Å—Ç–∞—Ç—É—Å—ã –∑–∞–¥–∞—á
4. –°–æ–∑–¥–∞–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç—á—ë—Ç —Å —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–º –ø–æ—Ä—è–¥–∫–æ–º

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
# –ê–Ω–∞–ª–∏–∑ –∑–∞–¥–∞—á –∏–∑ Yandex Tracker

## –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

1. [KEY] - –ù–∞–∑–≤–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏
   –ü—Ä–∏—á–∏–Ω–∞: [–æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø–æ—á–µ–º—É —ç—Ç–∞ –∑–∞–¥–∞—á–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ø–µ—Ä–≤–æ–π]
   –°—Ç–∞—Ç—É—Å: [—Ç–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å]

2. [KEY] - –ù–∞–∑–≤–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏
   –ü—Ä–∏—á–∏–Ω–∞: [–æ–±—ä—è—Å–Ω–µ–Ω–∏–µ]
   –°—Ç–∞—Ç—É—Å: [—Ç–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å]

[–∏ —Ç–∞–∫ –¥–∞–ª–µ–µ...]

## –í—ã–≤–æ–¥—ã:
[–ö—Ä–∞—Ç–∫–∏–µ –≤—ã–≤–æ–¥—ã –æ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è—Ö –∏ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞—Ö]
"""

    messages = [
        {
            "role": "system",
            "content": "–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—é –ø—Ä–æ–µ–∫—Ç–∞–º–∏. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å –∑–∞–¥–∞—á–∏ –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—à—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ –∏—Ö –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è."
        },
        {
            "role": "user",
            "content": analysis_prompt
        }
    ]

    try:
        logger.info("Analyzing tasks with DeepSeek...")
        response_text, token_usage = call_deepseek_api(messages)
        logger.info(f"Task analysis completed. Tokens used: {token_usage['total_tokens']}")
        return response_text
    except Exception as e:
        logger.error(f"Error analyzing tasks: {e}")
        return f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–¥–∞—á: {str(e)}"


# MCP Client functions
async def call_mcp_tool(tool_name: str, arguments: dict = None):
    """–í—ã–∑–æ–≤ MCP tool —á–µ—Ä–µ–∑ WebSocket –∏ –ø–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞."""
    try:
        logger.info(f"Connecting to MCP server at {MCP_SERVER_URL}")
        async with websocket_client(MCP_SERVER_URL) as (read, write):
            logger.info("WebSocket connection established")
            async with ClientSession(read, write) as session:
                logger.info("MCP session created")

                # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å timeout
                await asyncio.wait_for(session.initialize(), timeout=10.0)
                logger.info("Session initialized")

                # –í—ã–∑–æ–≤ tool —Å timeout
                logger.info(f"Calling tool: {tool_name}")
                result = await asyncio.wait_for(
                    session.call_tool(tool_name, arguments or {}),
                    timeout=15.0
                )
                logger.info(f"Tool call completed")

                # –ò–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                if result.content and len(result.content) > 0:
                    logger.info(f"Result content: {len(result.content[0].text)} chars")
                    return result.content[0].text
                else:
                    logger.warning("No content in result")
                return None
    except asyncio.TimeoutError:
        logger.error(f"Timeout calling MCP tool: {tool_name}")
        return None
    except Exception as e:
        logger.error(f"Error calling MCP tool: {e}", exc_info=True)
        return None


def call_mcp_tool_sync(tool_name: str, arguments: dict = None):
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –≤—ã–∑–æ–≤–∞ async MCP tool."""
    loop = asyncio.new_event_loop()
    try:
        return loop.run_until_complete(call_mcp_tool(tool_name, arguments))
    finally:
        loop.close()


def call_mcp_tool_sync_on_server(server_url: str, tool_name: str, arguments: dict = None):
    """
    –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –≤—ã–∑–æ–≤–∞ MCP tool –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º —Å–µ—Ä–≤–µ—Ä–µ.

    Args:
        server_url: WebSocket URL –úCP —Å–µ—Ä–≤–µ—Ä–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, ws://localhost:8081/mcp)
        tool_name: –ò–º—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –¥–ª—è –≤—ã–∑–æ–≤–∞
        arguments: –ê—Ä–≥—É–º–µ–Ω—Ç—ã –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

    Returns:
        –¢–µ–∫—Å—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    async def call_tool_async():
        try:
            logger.info(f"Connecting to MCP server at {server_url}")
            async with websocket_client(server_url) as (read, write):
                logger.info("WebSocket connection established")
                async with ClientSession(read, write) as session:
                    logger.info("MCP session created")

                    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å timeout
                    await asyncio.wait_for(session.initialize(), timeout=10.0)
                    logger.info("Session initialized")

                    # –í—ã–∑–æ–≤ tool —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º timeout –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞
                    logger.info(f"Calling tool: {tool_name}")
                    result = await asyncio.wait_for(
                        session.call_tool(tool_name, arguments or {}),
                        timeout=30.0  # –î–ª–∏–Ω–Ω—ã–π timeout –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞
                    )
                    logger.info(f"Tool call completed")

                    if result.content and len(result.content) > 0:
                        return result.content[0].text
                    else:
                        logger.warning("No content in result")
                    return None
        except asyncio.TimeoutError:
            logger.error(f"Timeout calling {tool_name} on {server_url}")
            return None
        except Exception as e:
            logger.error(f"Error calling {tool_name} on {server_url}: {e}", exc_info=True)
            return None

    loop = asyncio.new_event_loop()
    try:
        return loop.run_until_complete(call_tool_async())
    finally:
        loop.close()


def execute_tasks_pipeline() -> dict:
    """
    –í—ã–ø–æ–ª–Ω–∏—Ç—å –ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω: –ü–æ–ª—É—á–∏—Ç—å –∑–∞–¥–∞—á–∏ -> –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å -> –ü–µ—Ä–µ–≤–µ—Å—Ç–∏.

    Returns:
        dict —Å–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π:
        {
            "success": bool,
            "step": str,  # –ü–æ—Å–ª–µ–¥–Ω–∏–π —É—Å–ø–µ—à–Ω—ã–π —à–∞–≥
            "tasks_json": str,
            "analysis": str,
            "translation": str,
            "error": str  # –ï—Å–ª–∏ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞
        }
    """
    result = {
        "success": False,
        "step": "none",
        "tasks_json": None,
        "analysis": None,
        "translation": None,
        "error": None
    }

    try:
        # –®–∞–≥ 1: –ü–æ–ª—É—á–∏—Ç—å –∑–∞–¥–∞—á–∏ –∏–∑ Yandex Tracker —á–µ—Ä–µ–∑ MCP Server 1
        logger.info("Pipeline Step 1: Fetching tasks from Yandex Tracker")
        tasks_json = call_mcp_tool_sync_on_server(
            MCP_SERVER_URL,
            "get-tracker-tasks"
        )

        if not tasks_json or "error" in tasks_json.lower():
            result["error"] = "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∑–∞–¥–∞—á–∏ –∏–∑ Yandex Tracker"
            result["step"] = "fetch_tasks"
            return result

        result["tasks_json"] = tasks_json
        result["step"] = "fetch_tasks"
        logger.info(f"Step 1 complete: Retrieved {len(tasks_json)} chars")

        # –®–∞–≥ 2: –ê–Ω–∞–ª–∏–∑ –∑–∞–¥–∞—á —Å –ø–æ–º–æ—â—å—é DeepSeek
        logger.info("Pipeline Step 2: Analyzing tasks with DeepSeek")
        analysis = analyze_tasks_order(tasks_json)

        if not analysis or "–æ—à–∏–±–∫–∞" in analysis.lower()[:100]:
            result["error"] = "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∑–∞–¥–∞—á–∏"
            result["step"] = "analyze_tasks"
            return result

        result["analysis"] = analysis
        result["step"] = "analyze_tasks"
        logger.info(f"Step 2 complete: Analysis {len(analysis)} chars")

        # –®–∞–≥ 3: –ü–µ—Ä–µ–≤–æ–¥ –Ω–∞ —ç—Å–ø–µ—Ä–∞–Ω—Ç–æ —á–µ—Ä–µ–∑ MCP Server 2
        logger.info("Pipeline Step 3: Translating to Esperanto")
        translation_response = call_mcp_tool_sync_on_server(
            MCP_SERVER2_URL,
            "translate-to-esperanto",
            {"text": analysis}
        )

        if not translation_response:
            # –ü–µ—Ä–µ–≤–æ–¥ –æ–ø—Ü–∏–æ–Ω–∞–ª–µ–Ω - –Ω–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞
            logger.warning("Translation failed, using Russian version")
            result["translation"] = None
            result["error"] = "–ü–µ—Ä–µ–≤–æ–¥ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
        else:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –≤–µ—Ä–Ω—É–ª–∞—Å—å –ª–∏ –æ—à–∏–±–∫–∞ –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ
            try:
                error_check = json.loads(translation_response)
                if isinstance(error_check, dict) and "error" in error_check:
                    logger.warning(f"Translation error: {error_check['error']}")
                    result["translation"] = None
                    result["error"] = "–ü–µ—Ä–µ–≤–æ–¥ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
                else:
                    result["translation"] = translation_response
                    logger.info(f"Step 3 complete: Translation {len(translation_response)} chars")
            except (json.JSONDecodeError, ValueError):
                # –ù–µ JSON - –∑–Ω–∞—á–∏—Ç —ç—Ç–æ –æ–±—ã—á–Ω—ã–π –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
                result["translation"] = translation_response
                logger.info(f"Step 3 complete: Translation {len(translation_response)} chars")

        result["success"] = True
        result["step"] = "complete"
        return result

    except Exception as e:
        logger.error(f"Pipeline error at step {result['step']}: {e}", exc_info=True)
        result["error"] = str(e)
        return result


def handle_rag_query(question: str, conversation_history: list = None, tracker_info: str = None) -> dict:
    """
    –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∑–∞–ø—Ä–æ—Å —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º RAG —Å —É—á—ë—Ç–æ–º –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞ –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ Tracker.

    Args:
        question: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        conversation_history: –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
                            –§–æ—Ä–º–∞—Ç: [{"role": "user"|"assistant"|"system", "content": str}]
        tracker_info: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–¥–∞—á–∞—Ö –∏–∑ Yandex Tracker (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –î–µ–Ω—å 22)

    Returns:
        dict —Å –æ—Ç–≤–µ—Ç–æ–º –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏:
        {
            "success": bool,
            "question": str,
            "answer": str,                  # –ï–¥–∏–Ω—ã–π –æ—Ç–≤–µ—Ç —Å RAG
            "relevant_chunks": list,        # –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ chunks
            "context": str,                 # RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç
            "tokens": dict,                 # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤
            "sources_formatted": str,       # –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
            "error": str
        }
    """
    result = {
        "success": False,
        "question": question,
        "answer": None,
        "relevant_chunks": [],
        "context": "",
        "tokens": {},
        "sources_formatted": "",
        "error": None
    }

    try:
        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å RAG
        if not RAG_AVAILABLE:
            result["error"] = "RAG module not available"
            return result

        logger.info(f"Processing RAG query with conversation history: '{question}'")

        # –ù–∞–π—Ç–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫–∏ –° —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π (hybrid mode)
        logger.info("Searching for relevant chunks with filtering...")
        context_text, chunks, filter_stats = rag_query(
            question,
            top_k=3,
            enable_filtering=True,
            filtering_mode="hybrid"
        )

        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –µ—Å—Ç—å –ª–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        if not chunks:
            logger.warning("All chunks filtered out - no relevant documentation found")
            result["success"] = True
            result["answer"] = (
                "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —è –Ω–µ –Ω–∞—à—ë–ª —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ "
                "Pond Mobile API –¥–ª—è –≤–∞—à–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å "
                "–∑–∞–ø—Ä–æ—Å –∏–ª–∏ —É—Ç–æ—á–Ω–∏—Ç—å –¥–µ—Ç–∞–ª–∏."
            )
            result["sources_formatted"] = "\nüìö –ò—Å—Ç–æ—á–Ω–∏–∫–∏: –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
            result["tokens"] = {"total_tokens": 0, "prompt_tokens": 0, "completion_tokens": 0}
            return result

        result["relevant_chunks"] = chunks
        result["context"] = context_text
        logger.info(f"Found {len(chunks)} relevant chunks")

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞
        history_context = ""
        if conversation_history:
            # –û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π
            MAX_HISTORY_MESSAGES = 10
            recent_history = conversation_history[-MAX_HISTORY_MESSAGES:]

            # –í–∑—è—Ç—å —Ç–æ–ª—å–∫–æ user/assistant —Å–æ–æ–±—â–µ–Ω–∏—è (–∏—Å–∫–ª—é—á–∏—Ç—å system)
            recent_messages = [
                msg for msg in recent_history
                if msg.get('role') in ['user', 'assistant']
            ]

            if recent_messages:
                history_parts = []
                for msg in recent_messages:
                    role = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å" if msg['role'] == 'user' else "–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç"
                    history_parts.append(f"{role}: {msg['content']}")

                history_context = "\n".join(history_parts)
                logger.info(f"Using conversation history: {len(recent_messages)} messages")

        # –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –ø—Ä–æ–º–ø—Ç —Å —É—á—ë—Ç–æ–º –∏—Å—Ç–æ—Ä–∏–∏ –∏ tracker info (–î–µ–Ω—å 22)
        system_message = {
            "role": "system",
            "content": (
                "–¢—ã ‚Äî AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Pond Mobile API. "
                "–ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞. "
                "–ï—Å–ª–∏ –µ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ Yandex Tracker –æ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö, –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —É–ø–æ–º—è–Ω–∏ –µ—ë. "
                "–£—á–∏—Ç—ã–≤–∞–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å. "
                "–ï—Å–ª–∏ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –Ω–µ—Ç –Ω—É–∂–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º, "
                "–Ω–æ –ø—Ä–æ–≤–µ—Ä—å, –µ—Å—Ç—å –ª–∏ –æ—Ç–∫—Ä—ã—Ç–∞—è –∑–∞–¥–∞—á–∞ –≤ Tracker –ø–æ —ç—Ç–æ–π —Ç–µ–º–µ. "
                "–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞: —Å–Ω–∞—á–∞–ª–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏, –∑–∞—Ç–µ–º —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á –∏–∑ Tracker. "
                "–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, —á—ë—Ç–∫–æ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ."
            )
        }

        # –°–æ–±—Ä–∞—Ç—å user message
        user_content_parts = []

        # –î–æ–±–∞–≤–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if history_context:
            user_content_parts.append(
                "=== –ö–û–ù–¢–ï–ö–°–¢ –ü–†–ï–î–´–î–£–©–ï–ì–û –î–ò–ê–õ–û–ì–ê ===\n" + history_context
            )

        # –î–æ–±–∞–≤–∏—Ç—å RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç
        user_content_parts.append(
            "=== –†–ï–õ–ï–í–ê–ù–¢–ù–ê–Ø –î–û–ö–£–ú–ï–ù–¢–ê–¶–ò–Ø ===\n" + context_text
        )

        # –î–µ–Ω—å 22: –î–æ–±–∞–≤–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ Tracker (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if tracker_info:
            user_content_parts.append(
                "=== –û–¢–ö–†–´–¢–´–ï –ó–ê–î–ê–ß–ò –ò–ó YANDEX TRACKER ===\n" + tracker_info
            )
            logger.info("Added Tracker context to RAG query")

        # –î–æ–±–∞–≤–∏—Ç—å —Ç–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å
        user_content_parts.append(
            f"=== –¢–ï–ö–£–©–ò–ô –í–û–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø ===\n{question}"
        )

        user_message = {
            "role": "user",
            "content": "\n\n".join(user_content_parts)
        }

        messages = [system_message, user_message]

        # –í—ã–∑–≤–∞—Ç—å DeepSeek API
        logger.info("Calling DeepSeek API with RAG context and conversation history...")
        answer, tokens = call_deepseek_api(messages)

        result["answer"] = answer
        result["tokens"] = tokens
        logger.info(f"Answer generated: {len(answer)} chars, {tokens['total_tokens']} tokens")

        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏
        result["sources_formatted"] = format_sources_for_telegram(chunks)

        result["success"] = True
        return result

    except Exception as e:
        logger.error(f"Error in RAG query with conversation history: {e}", exc_info=True)
        result["error"] = str(e)
        return result


def format_sources_for_telegram(chunks: list) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–ª—è –≤—ã–≤–æ–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –≤ Telegram.

    Args:
        chunks: –°–ø–∏—Å–æ–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏

    Returns:
        –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ —Å –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏
    """
    if not chunks:
        return "\nüìö –ò—Å—Ç–æ—á–Ω–∏–∫–∏: –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"

    sources_parts = ["\n" + "="*40]
    sources_parts.append("üìö –ò–°–¢–û–ß–ù–ò–ö–ò")
    sources_parts.append("="*40)

    # –ü–æ–∫–∞–∑–∞—Ç—å –æ–±—â–∏–π –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
    sources_parts.append("\nüìñ –ò—Å—Ç–æ—á–Ω–∏–∫: OpenAPI —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è Pond Mobile API")
    sources_parts.append("üìÅ –§–∞–π–ª: resources/dist.json")

    return "\n".join(sources_parts)


def format_rag_response_for_telegram(rag_result: dict) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç RAG-–∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –≤—ã–≤–æ–¥–∞ –≤ Telegram.

    Args:
        rag_result: –†–µ–∑—É–ª—å—Ç–∞—Ç handle_rag_query()

    Returns:
        –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è Telegram
    """
    parts = []

    # 1. –û—Ç–≤–µ—Ç –æ—Ç LLM
    parts.append(rag_result['answer'])

    # 2. –ò—Å—Ç–æ—á–Ω–∏–∫–∏
    parts.append(rag_result['sources_formatted'])

    # 3. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤
    tokens = rag_result['tokens']
    parts.append(
        f"\n{'='*40}\n"
        f"üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê\n"
        f"{'='*40}\n"
        f"‚Ä¢ –¢–æ–∫–µ–Ω–æ–≤ –≤ –∑–∞–ø—Ä–æ—Å–µ: {tokens['prompt_tokens']}\n"
        f"‚Ä¢ –¢–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ: {tokens['completion_tokens']}\n"
        f"‚Ä¢ –í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤: {tokens['total_tokens']}"
    )

    return "\n".join(parts)


def send_long_message(update: Update, message: str, max_length: int = 4000):
    """
    –û—Ç–ø—Ä–∞–≤–∏—Ç—å –¥–ª–∏–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, —Ä–∞–∑–±–∏–≤–∞—è –ø–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏.

    Args:
        update: Telegram update
        message: –°–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏
        max_length: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ–¥–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
    """
    if len(message) <= max_length:
        update.message.reply_text(message)
        return

    # –†–∞–∑–±–∏—Ç—å –ø–æ —Å–µ–∫—Ü–∏—è–º (–ø–æ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º "===")
    sections = message.split("="*40)

    current_part = ""
    for i, section in enumerate(sections):
        section_with_separator = ("="*40 + section) if i > 0 else section

        if len(current_part) + len(section_with_separator) > max_length:
            if current_part:
                update.message.reply_text(current_part)
            current_part = section_with_separator
        else:
            current_part += section_with_separator

    if current_part:
        update.message.reply_text(current_part)


def send_tasks_summary(context: CallbackContext):
    """–û—Ç–ø—Ä–∞–≤–∫–∞ —Å–≤–æ–¥–∫–∏ –∑–∞–¥–∞—á –∫–∞–∂–¥—ã–µ N –º–∏–Ω—É—Ç."""
    if 'admin_chat_id' not in context.bot_data:
        logger.warning("admin_chat_id not set, skipping summary")
        return

    try:
        # –ü–æ–ª—É—á–∞–µ–º –∑–∞–¥–∞—á–∏ —á–µ—Ä–µ–∑ MCP
        tasks_json = call_mcp_tool_sync("get-tracker-tasks")

        if not tasks_json:
            logger.error("Failed to get tasks from MCP")
            return

        # –ü–∞—Ä—Å–∏–º JSON
        tasks = json.loads(tasks_json)

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å–≤–æ–¥–∫—É
        if isinstance(tasks, dict) and 'error' in tasks:
            summary = f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∑–∞–¥–∞—á:\n{tasks['error']}"
        elif isinstance(tasks, list):
            if len(tasks) == 0:
                summary = "üìã –ó–∞–¥–∞—á –≤ Yandex Tracker –Ω–µ—Ç"
            else:
                summary = f"üìã –°–≤–æ–¥–∫–∞ –∑–∞–¥–∞—á –∏–∑ Yandex Tracker ({len(tasks)} —à—Ç.):\n\n"
                for task in tasks[:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –º–∞–∫—Å–∏–º—É–º 10 –∑–∞–¥–∞—á
                    summary += f"üîπ {task.get('key')}: {task.get('summary')}\n"
                    summary += f"   –°—Ç–∞—Ç—É—Å: {task.get('status')}\n"
                    summary += f"   –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å: {task.get('assignee')}\n\n"

                if len(tasks) > 10:
                    summary += f"\n... –∏ –µ—â—ë {len(tasks) - 10} –∑–∞–¥–∞—á(–∏)"
        else:
            summary = f"üìã –ü–æ–ª—É—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ:\n{tasks_json[:500]}"

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º
        context.bot.send_message(
            chat_id=context.bot_data['admin_chat_id'],
            text=summary
        )
        logger.info(f"Sent tasks summary to {context.bot_data['admin_chat_id']}")

    except Exception as e:
        logger.error(f"Error in send_tasks_summary: {e}", exc_info=True)


def error_handler(update: Update, context: CallbackContext) -> None:
    """Log errors caused by updates."""
    logger.error(f"Update {update} caused error {context.error}")

def main() -> None:
    """Start the bot."""
    if not TOKEN:
        logger.error("TELEGRAM_BOT_TOKEN not found in environment variables")
        return

    # Create the Updater and pass it your bot's token.
    updater = Updater(TOKEN)

    # Get the dispatcher to register handlers
    dispatcher = updater.dispatcher

    # Register handlers
    dispatcher.add_handler(CommandHandler("start", start))
    dispatcher.add_handler(CommandHandler("help", help_command))
    dispatcher.add_handler(CommandHandler("stats", stats_command))
    dispatcher.add_handler(CommandHandler("compress", compress_command))
    dispatcher.add_handler(CommandHandler("clear", clear_command))
    dispatcher.add_handler(MessageHandler(Filters.text & ~Filters.command, ask_question))

    # Add error handler
    dispatcher.add_error_handler(error_handler)

    # Add periodic job for tasks summary (every 2 minutes = 120 seconds)
    # DISABLED: Regular task updates are disabled
    # job_queue = updater.job_queue
    # job_queue.run_repeating(send_tasks_summary, interval=120, first=120)
    # logger.info("Scheduled tasks summary job (every 2 minutes)")

    # Start the Bot
    updater.start_polling()

    # Run the bot until you press Ctrl-C or the process receives SIGINT,
    # SIGTERM or SIGABRT. This should be used most of the time, since
    # start_polling() is non-blocking and will stop the bot gracefully.
    updater.idle()

if __name__ == '__main__':
    main()
